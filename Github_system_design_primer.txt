expected read to write ratio
requests per second

线性一致性(Linearizability) --> 顺序一致性(Sequential consistency) --> 因果一致性(Casual consistency) --> 最终一致性(Eventual consistency)

aim for maximal throughput with acceptable latency

Strong consistency (replicated synchronously) --> Eventual consistency (replicated asynchronously) --> Weak consistency

two complementary patterns to support high availability:
    fail-over
        Active-passive / master-slave
        Active-active / master-master
    replication
        Master-slave
        Master-master

commodity machines
Read replicas / Data federation (or functional partitioning) splits up databases by function / Object storage
get bogged down / greater replication lag
results in more cache hits due to improved cache locality
write in parallel, increasing throughput

Sharding / Common ways to shard a table of users is either through the user's last name initial or the user's geographic location / Re-balancing adds additional complexity
De-normalization attempts to improve read performance at the expense of some write performance / Redundant copies of the data are written in multiple tables to avoid expensive joins
reads can heavily outnumber writes

SQL tuning / benchmark and profile / Set the NOT NULL constraint where applicable to improve search performance / Use good indices

Popular items can skew the distribution, causing bottlenecks / Putting a cache in front of a database can help absorb uneven loads and spikes in traffic

When to update the cache
    Cache-aside
    Write-through
    Write-behind (write-back) / Add/update entry in cache. Asynchronously write entry to the data store, improving write performance
    Refresh-ahead

Cache-aside is also referred to as lazy loading. Only requested data is cached. / stale / time-to-live (TTL)
cache invalidation / the source of truth such as the database

consensus algorithms in distributed systems / two key principles: 1) two phase commit, and 2) quorum majority vote / Strong consistency
    - Paxos
    - Raft
    - ZAB (ZooKeeper Atomic BoardCast)
    - Gossip protocol (eventually consistency)
------------------------------------------------------------------------------------------------------------------------

cache hit / cache miss
notifications don't need to be instant
write to read ratio / Write-heavy
back-of-the-envelope usage calculations

NOT NULL / AUTO INCREMENT / PRIMARY KEY / FOREIGN KEY / UNIQUE / DEFAULT / CHECK
do this asynchronously with a queue / places a job on a Queue such as RabbitMQ / Pulls from the Queue / Uses a Queue to asynchronously send out notifications
storing the results as raw log files in the Object Store
calculate aggregate monthly spending by category
uses the Notification Service to let users know

Master-Slave Replicas / SQL Read Replicas / SQL write master-slave failover / Master-slave replication
tab delimited / Parse each log line
address bottlenecks while evaluating alternatives and trade-offs / how to iteratively scale the initial design
API server (application layer) / Web server (reverse proxy)

Memory Cache such as Redis or Memcached
Static content can be served from the Object Store such as Amazon S3 (Cloud Object Storage), which is cached on the CDN

create a separate Analytics Database using a data warehousing solution such as Amazon Redshift (Cloud Data Warehouse) or Google BigQuery
handling the unevenly distributed traffic and traffic spikes / the replicas are not bogged down with replicating writes
------------------------------------------------------------------------------------------------------------------------

Default setting / set a timed expiration
tracks analytics of pages / Monthly visit stats
Traffic is not evenly distributed / 10:1 read to write ratio

use a managed Object Store such as Amazon S3 or a NoSQL document store / use a NoSQL key-value store
creates an index / enforce uniqueness / speed up lookups
Take the MD5 hash of
    -- MD5 is a widely used hashing function that produces a 128-bit hash value
    -- MD5 is uniformly distributed

Base 62 (an encoding method with 62 characters) encode the MD5 hash
Base 64 is another popular encoding but provides issues for urls because of the additional + and / characters

Take the first 7 characters of the output /  possible values  / should be sufficient to handle our constraint of
traffic for popular content should be handled by the Memory Cache
------------------------------------------------------------------------------------------------------------------------

Popular queries / expire/refresh
use a least recently used (LRU) approach to expire older entries / Updates the cached entry's position to the front of the LRU list
the cache is at capacity
a cached entry / time to live (TTL)
------------------------------------------------------------------------------------------------------------------------

Store static content separately in an Object Store
bottlenecks during peak hours / resulting in slow responses / downtime
read-heavy vs write-heavy
automatically spinning up and down servers / Add Autoscaling to provision capacity as needed
unused instances / introduce complexity

Batch compute offline
Fanning out a tweet to all of your followers
more read heavy than write heavy
store media such as photos or videos on an Object Store
The high volume of writes would overwhelm
bandwidth intensive, ensure there is enough bandwidth to sustain high throughput
connection pooling
------------------------------------------------------------------------------------------------------------------------

Handy conversion guide:
   2.5 million seconds per month
   1 request per second = 2.5 million requests per month
   40 requests per second = 100 million requests per month
   400 requests per second = 1 billion requests per month

Spring Retry provides an ability to automatically re-invoke a failed operation.
This is helpful where the errors may be transient (like a momentary network glitch).

A materialized view is a pre-computed data set derived from a query specification (the SELECT in the view definition) and stored for later use.
Because the data is pre-computed, querying a materialized view is faster than executing a query against the base table of the view.

Rate limiting is a technique to limit network traffic to prevent users from exhausting system resources.
Rate limiting makes it harder for malicious actors to overburden the system and cause attacks like Denial of Service (DoS).

The Circuit Breaker design pattern is used to stop the request and response process if a service is not working.
A circuit breaker acts as a proxy for operations that might fail. The proxy should monitor the number of recent failures that have occurred,
and use this information to decide whether to allow the operation to proceed, or simply return an exception immediately.

Graceful degradation is the ability of a computer, machine, electronic system or network to maintain limited functionality
even when a large portion of it has been destroyed or rendered inoperative. The purpose of graceful degradation is to prevent catastrophic failure.

Stop cascading failures. Fallbacks and graceful degradation. Fail fast and rapid recovery.

Fallback: Use a different mechanism to achieve the same result.
Fallback Mechanism: If a CDN fails, you should be able to detect it and start sending requests for resources from the original web server.

Circuit Breaker status:
   - open
   - close
   - trip
   - half-open
Circuit Breaker -> Fallback
Hystrix: a library designed to control the interactions between these distributed services providing greater tolerance of latency and failure.
------------------------------------------------------------------------------------------------------------------------
Throttling Algorithms
    - token bucket algorithm
    - leaky bucket algorithm

Guava RateLimiter
    - SmoothBursty
    - SmoothWarmingUp: has a warm-up period after teh startup. It gradually increases the distribution rate to the configured value.

Cache Problems
    - Cache Penetration
    - Cache Breakdown
    - Cache Avalanche

Bulkhead: Bulkhead pattern is a type of application design that is tolerant of failure.
          In a bulkhead architecture, elements of an application are isolated into pools so that if one fails, the others will continue to function.

Paxos (分布式一致性算法, 即一个分布式系统中的各个进程如何就某个值(决议)达成一致) is a family of protocols for solving consensus in a network of unreliable or fallible processors
Multi-Paxos: Multi-paxos is an optimization on using Paxos for consecutive rounds, where you can skip one of the phases if you assume a stable leader.
Raft is a consensus algorithm designed as an alternative to the Paxos family of algorithms. A distributed SQL database uses the Raft consensus algorithm for both leader election and data replication.
Zab is a crash-recovery atomic broadcast algorithm we designed for the ZooKeeper coordination service. It uses a quorum of followers to act as its distributed memory, resilient to crash failures.

全局唯一ID实现方案
    - UUID
        > 不易于存储：UUID太长, 16字节128位, 通常以36长度的字符串表示, 很多场景不适用
        > 信息不安全：基于MAC地址生成UUID的算法可能会造成MAC地址泄露, 暴露使用者的位置
        > 对MySQL索引不利：如果作为数据库主键, 在InnoDB引擎下, UUID的无序性可能会引起数据位置频繁变动, 严重影响性能, 可以查阅Mysql索引原理B+树的知识
    - 数据库生成
        > 强依赖DB, 当DB异常时整个系统不可用。虽然配置主从复制可以尽可能的增加可用性, 但是数据一致性在特殊情况下难以保证。主从切换时的不一致可能会导致重复发号
        > ID发号性能瓶颈限制在单台MySQL的读写性能
    - 使用redis实现
        > INCR和INCRBY这样的自增原子命令
        > Redis自身的单线程的特点所以能保证生成的ID肯定是唯一有序的
        > 性能比较高，生成的数据是有序的，对排序业务有利
        > 但是单机存在性能瓶颈, 无法满足高并发的业务需求, 所以可以采用集群的方式来实现, 增加了系统的配置复杂性
    - 雪花算法 Snowflake
        > Snowflake IDs, or snowflakes, are a form of unique identifier used in distributed computing.
        > 64-bit: 在Java中SnowFlake算法生成的ID就是long来存储的
        > 由于long基本类型在Java中是带符号的，最高位是符号位，正数是0，负数是1，所以id一般是正数，最高位是0
        > 第1位占用1bit，其值始终是0，可看做是符号位不使用。
        > 第2位开始的41位是时间戳，41-bit位可表示2^41个数，每个数代表毫秒，那么雪花算法可用的时间年限是(1L<<41)/(1000L360024*365)=69 年的时间。
        > 中间的10-bit位可表示机器数，即2^10 = 1024台机器，但是一般情况下我们不会部署这么台机器。如果我们对IDC（互联网数据中心）有需求，还可以将10-bit分5-bit给IDC，分5-bit给工作机器。这样就可以表示32个IDC，每个IDC下可以有32台机器，具体的划分可以根据自身需求定义。
        > 最后12-bit位是自增序列，可表示2^12 = 4096个数。
        > 这样的划分之后相当于在一毫秒一个数据中心的一台机器上可产生4096个有序的不重复的ID。但是我们IDC和机器数肯定不止一个，所以毫秒内能生成的有序ID数是翻倍的。
        > SnowFlake的优点是，整体上按照时间自增排序，并且整个分布式系统内不会产生ID碰撞(由数据中心ID和机器ID作区分)，并且效率较高，经测试，SnowFlake每秒能够产生26万ID左右
        > 但是雪花算法强依赖机器时钟，如果机器上时钟回拨，会导致发号重复或者服务会处于不可用状态。如果恰巧回退前生成过一些ID，而时间回退后，生成的ID就有可能重复。
          官方对于此并没有给出解决方案，而是简单的抛错处理，这样会造成在时间被追回之前的这段时间服务不可用

布隆过滤器(Bloom Filter)
    - 优点: 占用空间小，查询快
    - 缺点: 有误判，删除困难
    - 应用场景
        > 网页爬虫对URL的去重: 避免爬取相同的URL地址
        > 缓存击穿: 将已存在的缓存放到布隆中，当黑客访问不存在的缓存时迅速返回避免缓存及DB挂掉
        > Key-Value系统: 在很多Key-Value系统中也使用了布隆过滤器来加快查询过程
    - guava: com.google.common.hash.BloomFilter
    - 误报率: 出现了False Positive的情况, 但Bloom Filter不会出现False Negative的情况

摘要算法: A message digest algorithm or a hash function, is a procedure that maps input data of an arbitrary length to an output of fixed length
    - 消息摘要算法的主要特征是加密过程不需要密钥，并且经过加密的数据无法被解密
    - 只有输入相同的明文数据经过相同的消息摘要算法才能得到相同的密文
    - 消息摘要算法主要应用在“数字签名”领域，作为对明文的摘要算法
    - 著名的摘要算法有RSA公司的MD5算法和SHA-1算法及其大量的变体
    - 特点
        > 无论输入的消息有多长，计算出来的消息摘要的长度总是固定的
        > 消息摘要看起来是“伪随机的”。也就是说对相同的信息求摘要结果相同
        > 消息轻微改变生成的摘要变化会很大
        > 只能进行正向的信息摘要，而无法从摘要中恢复出任何的消息，甚至根本就找不到任何与原信息相关的信息
    - 应用
        > 消息摘要算法最常用的场景就是数字签名以及数据(密码)加密了
        > 一般平时做项目用的比较多的就是使用MD5对用户密码进行加密
    - MD5
        > JDK提供java.security.MessageDigest类实现MD5算法
        > used hash function producing a 128-bit hash value
    - SHA1
        > JDK提供java.security.MessageDigest类实现SHA1算法
        > produces a 160-bit (20-byte) hash value known as a message digest – typically rendered as 40 hexadecimal digits

Symmetric algorithm: DES / Data Encryption Standard
   - 因为DES使用56位密钥，以现代计算能力，24小时内即可被破解。虽然如此，在某些简单应用中，我们还是可以使用DES加密算法
   - JDK javax.crypto
Asymmetric algorithm: RSA (Public-key cryptography)
