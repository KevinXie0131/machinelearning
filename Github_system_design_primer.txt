expected read to write ratio
requests per second

线性一致性(Linearizability) --> 顺序一致性(Sequential consistency) --> 因果一致性(Casual consistency) --> 最终一致性(Eventual consistency)

aim for maximal throughput with acceptable latency

Strong consistency (replicated synchronously) --> Eventual consistency (replicated asynchronously) --> Weak consistency

two complementary patterns to support high availability:
    fail-over
        Active-passive / master-slave
        Active-active / master-master
    replication
        Master-slave
        Master-master

commodity machines
Read replicas / Data federation (or functional partitioning) splits up databases by function / Object storage
get bogged down / greater replication lag
results in more cache hits due to improved cache locality
write in parallel, increasing throughput

Sharding / Common ways to shard a table of users is either through the user's last name initial or the user's geographic location / Re-balancing adds additional complexity
De-normalization attempts to improve read performance at the expense of some write performance / Redundant copies of the data are written in multiple tables to avoid expensive joins
reads can heavily outnumber writes

SQL tuning / benchmark and profile / Set the NOT NULL constraint where applicable to improve search performance / Use good indices

Popular items can skew the distribution, causing bottlenecks / Putting a cache in front of a database can help absorb uneven loads and spikes in traffic

When to update the cache
    Cache-aside
    Write-through
    Write-behind (write-back) / Add/update entry in cache. Asynchronously write entry to the data store, improving write performance
    Refresh-ahead

Cache-aside is also referred to as lazy loading. Only requested data is cached. / stale / time-to-live (TTL)
cache invalidation / the source of truth such as the database

consensus algorithms in distributed systems / two key principles: 1) two phase commit, and 2) quorum majority vote / Strong consistency
    - Paxos
    - Raft
    - ZAB (ZooKeeper Atomic BoardCast)
    - Gossip protocol (eventually consistency)
------------------------------------------------------------------------------------------------------------------------

cache hit / cache miss
notifications don't need to be instant
write to read ratio / Write-heavy
back-of-the-envelope usage calculations

NOT NULL / AUTO INCREMENT / PRIMARY KEY / FOREIGN KEY / UNIQUE / DEFAULT / CHECK
do this asynchronously with a queue / places a job on a Queue such as RabbitMQ / Pulls from the Queue / Uses a Queue to asynchronously send out notifications
storing the results as raw log files in the Object Store
calculate aggregate monthly spending by category
uses the Notification Service to let users know

Master-Slave Replicas / SQL Read Replicas / SQL write master-slave failover / Master-slave replication
tab delimited / Parse each log line
address bottlenecks while evaluating alternatives and trade-offs / how to iteratively scale the initial design
API server (application layer) / Web server (reverse proxy)

Memory Cache such as Redis or Memcached
Static content can be served from the Object Store such as Amazon S3 (Cloud Object Storage), which is cached on the CDN

create a separate Analytics Database using a data warehousing solution such as Amazon Redshift (Cloud Data Warehouse) or Google BigQuery
handling the unevenly distributed traffic and traffic spikes / the replicas are not bogged down with replicating writes
------------------------------------------------------------------------------------------------------------------------

Default setting / set a timed expiration
tracks analytics of pages / Monthly visit stats
Traffic is not evenly distributed / 10:1 read to write ratio

use a managed Object Store such as Amazon S3 or a NoSQL document store / use a NoSQL key-value store
creates an index / enforce uniqueness / speed up lookups
Take the MD5 hash of
    -- MD5 is a widely used hashing function that produces a 128-bit hash value
    -- MD5 is uniformly distributed

Base 62 (an encoding method with 62 characters) encode the MD5 hash
Base 64 is another popular encoding but provides issues for urls because of the additional + and / characters

Take the first 7 characters of the output /  possible values  / should be sufficient to handle our constraint of
traffic for popular content should be handled by the Memory Cache
------------------------------------------------------------------------------------------------------------------------

Popular queries / expire/refresh
use a least recently used (LRU) approach to expire older entries / Updates the cached entry's position to the front of the LRU list
the cache is at capacity
a cached entry / time to live (TTL)
------------------------------------------------------------------------------------------------------------------------

Store static content separately in an Object Store
bottlenecks during peak hours / resulting in slow responses / downtime
read-heavy vs write-heavy
automatically spinning up and down servers / Add Autoscaling to provision capacity as needed
unused instances / introduce complexity

Batch compute offline
Fanning out a tweet to all of your followers
more read heavy than write heavy
store media such as photos or videos on an Object Store
The high volume of writes would overwhelm
bandwidth intensive, ensure there is enough bandwidth to sustain high throughput
connection pooling
------------------------------------------------------------------------------------------------------------------------

Handy conversion guide:
   2.5 million seconds per month
   1 request per second = 2.5 million requests per month
   40 requests per second = 100 million requests per month
   400 requests per second = 1 billion requests per month

Spring Retry provides an ability to automatically re-invoke a failed operation.
This is helpful where the errors may be transient (like a momentary network glitch).

A materialized view is a pre-computed data set derived from a query specification (the SELECT in the view definition) and stored for later use.
Because the data is pre-computed, querying a materialized view is faster than executing a query against the base table of the view.

Rate limiting is a technique to limit network traffic to prevent users from exhausting system resources.
Rate limiting makes it harder for malicious actors to overburden the system and cause attacks like Denial of Service (DoS).

The Circuit Breaker design pattern is used to stop the request and response process if a service is not working.
A circuit breaker acts as a proxy for operations that might fail. The proxy should monitor the number of recent failures that have occurred,
and use this information to decide whether to allow the operation to proceed, or simply return an exception immediately.
