expected read to write ratio
requests per second

线性一致性(Linearizability) --> 顺序一致性(Sequential consistency) --> 因果一致性(Casual consistency) --> 最终一致性(Eventual consistency)

aim for maximal throughput with acceptable latency

Strong consistency (replicated synchronously) --> Eventual consistency (replicated asynchronously) --> Weak consistency

two complementary patterns to support high availability:
    fail-over
        Active-passive / master-slave
        Active-active / master-master
    replication
        Master-slave
        Master-master

commodity machines
Read replicas / Data federation (or functional partitioning) splits up databases by function / Object storage
get bogged down / greater replication lag
results in more cache hits due to improved cache locality
write in parallel, increasing throughput

Sharding / Common ways to shard a table of users is either through the user's last name initial or the user's geographic location / Re-balancing adds additional complexity
De-normalization attempts to improve read performance at the expense of some write performance / Redundant copies of the data are written in multiple tables to avoid expensive joins
reads can heavily outnumber writes

SQL tuning / benchmark and profile / Set the NOT NULL constraint where applicable to improve search performance / Use good indices

Popular items can skew the distribution, causing bottlenecks / Putting a cache in front of a database can help absorb uneven loads and spikes in traffic

When to update the cache
    Cache-aside
    Write-through
    Write-behind (write-back) / Add/update entry in cache. Asynchronously write entry to the data store, improving write performance
    Refresh-ahead

Cache-aside is also referred to as lazy loading. Only requested data is cached. / stale / time-to-live (TTL)
cache invalidation / the source of truth such as the database








