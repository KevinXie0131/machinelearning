expected read to write ratio
requests per second

线性一致性(Linearizability) --> 顺序一致性(Sequential consistency) --> 因果一致性(Casual consistency) --> 最终一致性(Eventual consistency)

aim for maximal throughput with acceptable latency

Strong consistency (replicated synchronously) --> Eventual consistency (replicated asynchronously) --> Weak consistency

two complementary patterns to support high availability:
    fail-over
        Active-passive / master-slave
        Active-active / master-master
    replication
        Master-slave
        Master-master

commodity machines
Read replicas / Data federation (or functional partitioning) splits up databases by function / Object storage
get bogged down / greater replication lag
results in more cache hits due to improved cache locality
write in parallel, increasing throughput

Sharding / Common ways to shard a table of users is either through the user's last name initial or the user's geographic location / Re-balancing adds additional complexity
De-normalization attempts to improve read performance at the expense of some write performance / Redundant copies of the data are written in multiple tables to avoid expensive joins
reads can heavily outnumber writes

SQL tuning / benchmark and profile / Set the NOT NULL constraint where applicable to improve search performance / Use good indices

Popular items can skew the distribution, causing bottlenecks / Putting a cache in front of a database can help absorb uneven loads and spikes in traffic

When to update the cache
    Cache-aside
    Write-through
    Write-behind (write-back) / Add/update entry in cache. Asynchronously write entry to the data store, improving write performance
    Refresh-ahead

Cache-aside is also referred to as lazy loading. Only requested data is cached. / stale / time-to-live (TTL)
cache invalidation / the source of truth such as the database

consensus algorithms in distributed systems / two key principles: 1) two phase commit, and 2) quorum majority vote / Strong consistency
    - Paxos
    - Raft
    - ZAB (ZooKeeper Atomic BoardCast)
    - Gossip protocol (eventually consistency)
------------------------------------------------------------------------------------------------------------------------

cache hit / cache miss
notifications don't need to be instant
write to read ratio / Write-heavy
back-of-the-envelope usage calculations

NOT NULL / AUTO INCREMENT / PRIMARY KEY / FOREIGN KEY / UNIQUE / DEFAULT / CHECK
do this asynchronously with a queue / places a job on a Queue such as RabbitMQ / Pulls from the Queue / Uses a Queue to asynchronously send out notifications
storing the results as raw log files in the Object Store
calculate aggregate monthly spending by category
uses the Notification Service to let users know

Master-Slave Replicas / SQL Read Replicas / SQL write master-slave failover / Master-slave replication
tab delimited / Parse each log line
address bottlenecks while evaluating alternatives and trade-offs / how to iteratively scale the initial design
API server (application layer) / Web server (reverse proxy)

Memory Cache such as Redis or Memcached
Static content can be served from the Object Store such as Amazon S3 (Cloud Object Storage), which is cached on the CDN

create a separate Analytics Database using a data warehousing solution such as Amazon Redshift (Cloud Data Warehouse) or Google BigQuery
handling the unevenly distributed traffic and traffic spikes / the replicas are not bogged down with replicating writes
------------------------------------------------------------------------------------------------------------------------

Default setting / set a timed expiration
tracks analytics of pages / Monthly visit stats
Traffic is not evenly distributed / 10:1 read to write ratio

use a managed Object Store such as Amazon S3 or a NoSQL document store / use a NoSQL key-value store
creates an index / enforce uniqueness / speed up lookups
Take the MD5 hash of
    -- MD5 is a widely used hashing function that produces a 128-bit hash value
    -- MD5 is uniformly distributed

Base 62 (an encoding method with 62 characters) encode the MD5 hash
Base 64 is another popular encoding but provides issues for urls because of the additional + and / characters
