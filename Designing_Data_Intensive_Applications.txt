Scalability / Fault tolerance / High availability / Latency

Shared-Nothing Architectures (horizontal scaling / scaling out)
node / multiple geographic regions

Replication - redundancy (multiple copies of the same data on different nodes)
reduce latency / increase availability / increase read throughput
single-leader / multi-leader / leaderless replication
synchronous / asynchronous / semi-synchronous replication - durability / consensus

eventual consistency
read-your-writes / mono‐tonic reads guarantees

replica - leader-based replication - active/passive / master–slave replication
leader (master / primary)
followers (read replicas / slaves / secondaries / hot standbys) - replication log or change stream

Setting Up New Followers / downtime / snapshot / caught up
go down / high availability
Follower failure: Catch-up recovery

Leader failure: Failover
1. Determining that the leader has failed / timeout
2. Choosing a new leader / election / elected controller node / consensus
3. Reconfiguring the system to use the new leader / Request Routing

Discarding writes / lagged behind / be disclosed to / split brain / resolving conflicts / temporary load spike / network glitch

Implementation of Replication Logs
Statement-based replication / nondeterministic function / auto-incrementing column
Write-ahead log (WAL) shipping: A write ahead log is an append-only auxiliary disk-resident structure used for crash and transaction recovery.
                                The changes are first recorded in the log, which must be written to stable storage, before the changes are written to the database.
Logical (row-based) log replication
Trigger-based replication / triggers & stored procedures

Problems with Replication Lag / eventual consistency

Reading Your Own Writes / stale replica / read-after-write consistency / read-your-writes consistency / logical timestamp
Monotonic Reads / moving backward in time / little|greater lag / fresh|stale replica / anomaly
Consistent Prefix Reads / replication lag anomalies concerns violation of causality / a sequence of writes happens in a certain order / written to the same partition

Solutions for Replication Lag / transactions abandoned

Multi-Leader Replication (master–master / active/active replication)) / across multiple datacenters / single-leader based replication
Performance / Tolerance of datacenter outages / Tolerance of network problems
conflict resolution / auto-incrementing keys / triggers / integrity constraints
Clients with offline operation / synced with / Collaborative editing / Real-time collaborative editing
Handling Write Conflicts / committed changes / released the lock / Conflict avoidance
Converging toward a consistent state / unique ID (timestamp, long random number, UUID, hash) / last write wins (LWW)
Custom conflict resolution logic / On write / On read
replication topology / all-to-all / circular / star

version vectors / conflict detection

Leaderless Replication (Clients send each write to several nodes, and read from several nodes in parallel in order to detect and correct nodes with stale data.)
Dynamo-style / coordinator / A quorum write, quorum read, and read repair after a node outage / read requests are also sent to several nodes in parallel
stale (outdated)
Read repair / Anti-entropy process
Quorums for reading and writing / w + r > n /  w = r = (n + 1) / 2 (rounded up)
Limitations of Quorum Consistency / clock skew
Monitoring staleness / tolerate stale reads / replication lag / measure replica staleness
Sloppy Quorums and Hinted Handoff
Cross-datacenter replication

Detecting Concurrent Writes / Last write wins (discarding concurrent writes) / order is undefined / achieve eventual convergence
The 'happens-before' relationship and concurrency / B is causally dependent on A / causal dependencies between / get overwritten eventually
Merging concurrently written values / Merging sibling values / deletion marker is known as tombstone
Version vectors (also called a vector clock):
    A version vector is a mechanism for tracking changes to data in a distributed system, where multiple agents might update the data at different times.
------------------------------------------------------------------------------------------------------------------------

Partitioning - sharding
scalability (Different partitions can be placed on different nodes)
re-balancing / route requests to

Combining replication and partitioning: each node acts as leader for some partitions and follower for other partitions.
Partitioning of Key-Value Data / read & write throughput
skewed / hot spot

Partitioning by Key Range - Key range partitioning (partition boundaries need to adapt to the data to distribute the data evenly) / lead to hot spots / prefix each timestamp
Partitioning by Hash of Key - Hash partitioning (hash function to determine the partition for a given key) / MD5 / consistent hashing / hash partitioning (a particular approach to re-balancing)
lose the ability to do efficient range queries / sort order is lost
compound primary key / concatenated index for sorting the data

Skewed Workloads and Relieving Hot Spots

Partitioning and Secondary Indexes
Partitioning Secondary Indexes by Document / local index / document-partitioned / scatter/gather
Partitioning Secondary Indexes by Term / global index / term-partitioned

Re-balancing Partitions
Strategies for Re-balancing
hash mod N (not do it) / Fixed number of partitions / Dynamic partitioning (pre-splitting) / Partitioning proportionally to nodes

cascading failure / have a human in the loop

Request Routing / service discovery / round-robin load balancer / routing tier / partition-aware load balancer / achieving consensus in a distributed system
separate / external coordination service such as ZooKeeper to keep track of this cluster metadata
Each node registers itself in ZooKeeper, and ZooKeeper maintains the authoritative mapping of partitions to nodes
subscribe to this information in ZooKeeper.
When a node is added or removed, ZooKeeper notifies the routing tier so that it can keep its routing information up to date
use ZooKeeper to track partition assignment / for cluster management

gossip protocol:
    A gossip protocol or epidemic protocol is a procedure or process of computer peer-to-peer communication that is based on the way epidemics spread.
    Some distributed systems use peer-to-peer gossip to ensure that data is disseminated to all members of a group.
massively parallel processing (MPP) / join, filtering, grouping, aggregation operations
choosing a partitioning scheme

In Key range partitioning, partitions are typically rebalanced dynamically by splitting the range into two sub-ranges when a partition gets too big.
In Hash partitioning, it is common to create a fixed number of partitions in advance, to assign several partitions to each node, and to move entire partitions
    from one node to another when nodes are added or removed.
Hash partitioning - compound key: using one part of the key to identify the partition and another part for the sort order
------------------------------------------------------------------------------------------------------------------------

Transactions (group several reads and writes together into a logical unit. either the entire transaction succeeds (commit) or it fails (abort, rollback))
safety guarantees / transactional guarantees / catastrophic failure / fault-tolerance mechanisms
concurrency control / race conditions
isolation levels - read committed, snapshot isolation, and serializability
large-scale system / advantages / limitations / trade-offs

ACID (fault-tolerance) - Atomicity (abortability), Consistency, Isolation (serializability), Durability
BASE - Basically Available, Soft state, Eventual consistency
Atomicity: atomic refers to something that cannot be broken down into smaller parts / atomicity is not about concurrency / covered under isolation
           Atomicity simplifies this problem: if a transaction was aborted, the application can be sure that it didn't change anything, so it can safely be retried
Consistency: consistency refers to an application-specific notion of the database being in a 'good state' / foreign key constraints / uniqueness constraints
Isolation: means that concurrently executing transactions are isolated from each other / concurrency problems (race conditions) / run serially (one after another)
           However, in practice, serializable isolation is rarely used, because it carries a performance penalty
           Oracle 11g: 'serializable' -> snapshot isolation (weaker guarantee)
Durability:

Single-Object and Multi-Object Operations
out of sync
Atomicity can be implemented using a log for crash recovery
isolation can be implemented using a lock on each object (allowing only one thread to access an object at any one time)

document databases lacking join functionality also encourage de-normalization
error handling mechanism isn't perfect:
    If the transaction actually succeeded, but the network failed while the server tried to acknowledge the successful commit to the client, then retrying the transaction causes it to be performed twice
    If the error is due to overload, retrying the transaction will make the problem worse, not better.
    It is only worth retrying after transient errors (for example due to deadlock, isolation violation, temporary network interruptions, and failover);
       after a permanent error (e.g., constraint violation) a retry would be pointless.

Weak (non-serializable) Isolation Levels:
    Read Committed
    Repeatable Read (Snapshot Isolation)
Strong Isolation Levels:
    Serializability: Two-Phase Locking (2PL)
    Serializable Snapshot Isolation (SSI)

transaction isolation (letting you pretend that no concurrency is happening)
serializable isolation means that the database guarantees that transactions have the same effect as if they ran serially (i.e., one at a time, without any concurrency)
Serializable isolation has a performance cost

Read Committed: The most basic level of transaction isolation / default setting in Oracle 11g
    no dirty reads: only see data that has been committed
    no dirty writes: only overwrite data that has been committed
Implementing read committed: using row-level locks
                             While the transaction is ongoing, any other transactions that read the object are simply given the old value.
                             Only when the new value is committed do transactions switch over to reading the new value.

Repeatable Read (Snapshot Isolation)
This anomaly is called a non-repeatable read or read skew / some situations, Backups and Analytic queries and integrity checks cannot tolerate such temporary inconsistency

snapshot isolation: each transaction reads from a consistent snapshot of the database / frozen at a particular point in time
snapshot isolation is a very useful feature in databases that need to support both small, fast read-write transactions and large, long-running read-only transactions (e.g., for backups or analytics).
    It allows read-only transactions to see the database in a consistent state at a particular point in time, without locking and interfering with read-write transactions.

Snapshot isolation is a popular feature: it is supported by PostgreSQL, MySQL with the InnoDB storage engine, Oracle, SQL Server

Implementing snapshot isolation: readers never block writers, and writers never block readers.
                                 multi-version concurrency control (MVCC) / maintains several versions of an object side by side
                                 transaction IDs / Visibility rules for observing a consistent snapshot

Snapshot isolation is called by different names. In Oracle it is called serializable, and in PostgreSQL and MySQL it is called repeatable read

Preventing Lost Updates (conflicts that can occur between concurrently writing transactions)
read-modify-write cycle (requires reading the current value, calculating the new value, and writing back the updated value)
a variety of solutions have been developed:
    Atomic write operations: implemented by taking an exclusive lock on the object when it is read so that no other transaction can read it until the update has been applied (cursor stability)
                             Another option is to simply force all atomic operations to be executed on a single thread.
    Explicit locking: explicitly lock objects that are going to be updated, then perform a read-modify-write cycle / introduce a race condition
    Automatically detecting lost updates: detects a lost update, abort the transaction and force it to retry its read-modify-write cycle / less error-prone
    Compare-and-set: If the current value does not match what you previously read, the update has no effect, and the read-modify-write cycle must be retried.
    Conflict resolution and replication: In replicated databases, preventing lost updates takes on another dimension.
                                         Since they have copies of the data on multiple nodes, and the data can potentially be modified concurrently on different nodes,
                                         some additional steps need to be taken to prevent lost updates.
          Locks & compare-and-set operations assume a single up-to-date copy of the data / Atomic operations can work well in a replicated context
          multi-leader / leaderless replication allow several writes to happen concurrently and replicate them asynchronously
          allow concurrent writes to create several conflicting versions of a value (siblings), and use application code or special data structures to resolve and merge these versions later.
          last write wins (LWW) conflict resolution method is prone to lost updates, but LWW is the default in many replicated databases.

Write Skew and Phantoms
    Write Skew (different transactions may update different objects concurrently) anomaly / causing an application bug
        need a constraint that involves multiple objects
        the second-best option in this case is probably to explicitly lock the rows that the transaction depends on.
    More examples of write skew:
        Meeting room booking system / avoid double-booking (not safe under snapshot isolation) / need serializable isolation
        Multiplayer game / use a unique constraint
        Claiming a username / not safe under snapshot isolation / a unique constraint (the second transaction is aborted due to violating the constraint)
        Preventing double-spending
    Phantoms causing write skew       phantom (a write in one transaction changes the result of a search query in another transaction)
        Snapshot isolation avoids phantoms in read-only queries, but in read-write transactions, phantoms can lead to particularly tricky cases of write skew
    Materializing conflicts (turns it into a lock conflict on a concrete set of rows that exist in the database) / A serializable isolation level is much preferable

Serializability
    Serializable isolation (the strongest isolation level)
    It guarantees that even though transactions may execute in parallel, the end result is the same as if they had executed one at a time, serially, without any concurrency
    the database prevents all possible race conditions.
    Techniques to implement:
        Actual Serial Execution / Literally executing transactions in a serial order / execute only one transaction at a time, in serial order, on a single thread.
            / RAM became cheap enough / keep the entire active dataset in memory / transactions are usually short / avoid the coordination overhead of locking
        Two-phase locking (only viable option)
        Optimistic concurrency control techniques such as serializable snapshot isolation

    Encapsulating transactions in stored procedures (the entire transaction code to the database ahead of time / execute fast / without waiting for any network or disk I/O)
        a transaction is committed within the same HTTP request / a transaction does not span multiple requests / A new HTTP request starts a new transaction.
        interactive style of transaction / disallow concurrency will lead to low throughput / process multiple transactions concurrently to get reasonable performance
    Pros and cons of stored procedures:
        languages haven't kept up with developments
        Code running in a database is difficult to manage
        A database is often much more performance-sensitive than an application server
        in-memory data / No wait for I/O / avoid the overhead of concurrency control mechanisms / good throughput on a single thread
    Partitioning
        each partition can have its own transaction processing thread running independently
        give each CPU core its own partition, which allows your transaction throughput to scale linearly with the number of CPU cores
        cross-partition transactions have additional coordination overhead
        Simple key-value data can often be partitioned easily / multiple secondary indexes require a lot of cross-partition coordination
    Summary of serial execution:
        Every transaction must be small and fast
        active dataset can fit in memory
        Write throughput must be low enough to be handled on a single CPU core
        Cross-partition transactions are possible, but cross-partition coordination has overhead

Two-Phase Locking (2PL)
        as soon as anyone wants to write (modify or delete) an object, exclusive access is required
        Reading an old version of the object is not acceptable under 2PL
        In 2PL, writers block other writers and readers
        2PL provides serializability, it protects against all the race conditions, including lost updates and write skew
     Implementation of two-phase locking / in shared mode or in exclusive mode / acquired | released the lock
        deadlock / automatically detects deadlocks between transactions and aborts one of them
     Performance of two-phase locking
        transaction throughput and response times of queries are significantly worse under two-phase locking than under weak isolation.
        quite unstable latencies / due to the overhead of acquiring and releasing all those lock / due to reduced concurrency
        transaction is aborted due to deadlock / wasted effort

     Predicate locks (works similarly to the shared/exclusive lock / belongs to all objects that match some search condition)
        exclusive lock  > shared lock

     Index-range locks (next-key locking) / lock a bigger range of objects than is strictly necessary to maintain serializability

Serializable Snapshot Isolation (SSI)
   Pessimistic versus optimistic concurrency control
       Two-phase locking is a so-called pessimistic concurrency control mechanism / mutual exclusion
       Serial execution is, in a sense, pessimistic to the extreme
       serializable snapshot isolation (SSI) is an optimistic concurrency control technique / SSI is based on snapshot isolation
       On top of snapshot isolation, SSI adds an algorithm for detecting serialization conflicts among writes and determining which transactions to abort.
   Decisions based on an outdated premise (a fact that was true at the beginning of the transaction, but may no longer be true)
       Detecting reads of a stale MVCC object version (uncommitted write occurred before the read)
       Detecting writes that affect prior reads (the write occurs after the read)
   Detecting stale MVCC reads
       multi-version concurrency control (MVCC)
       checks whether any of the ignored writes have now been committed. If so, the transaction must be aborted.
   Detecting writes that affect prior reads
       When a transaction writes to the database, it must look in the indexes for any other transactions that have recently read the affected data.
   Performance of serializable snapshot isolation
       trade-off is the granularity / bookkeeping overhead can become significant
       the big advantage of serializable snapshot isolation is that one transaction doesn't need to block waiting for locks held by another transaction
       (snapshot isolation, writers don’t block readers, and vice versa)
       more predictable and less variable
       read-only queries can run on a consistent snapshot without requiring any locks, which is very appealing for read-heavy workloads.
       serializable snapshot isolation is not limited to the throughput of a single CPU core

Summary
    reduced down to a simple transaction abort / concurrency control
    examples of race conditions:
        Dirty reads
            prevented by read committed isolation level
        Dirty writes
        Read skew (non-repeatable reads)
            prevented with snapshot isolation implemented with multi-version concurrency control (MVCC)
        Lost updates
            prevented by snapshot isolation / require a manual lock
        Write skew
            by the time the write is made, the premise of the decision is no longer true / Only serializable isolation prevents this anomaly.
        Phantom reads
            Snapshot isolation prevents / index-range locks

    different approaches to implementing serializable transactions:
        Literally executing transactions in a serial order
           If you can make each transaction very fast to execute, and the transaction throughput is low enough to process on a single CPU core, this is a simple and effective option.
        Two-phase locking
           standard way of implementing serializability, but it is avoided due to performance characteristics
        Serializable snapshot isolation (SSI)
           A fairly new & optimistic algorithm / allowing transactions to proceed without blocking.
           When a transaction wants to commit, it is checked, and it is aborted if the execution was not serializable.
------------------------------------------------------------------------------------------------------------------------

Distributed Systems / replica failover / replication lag / currency control for transactions
Faults / Partial Failures (non-deterministic / non-determinism) / deterministic (the same operation always produces the same result) / fully functional / unpredictably fail
cloud computing / multi-tenant datacenters / commodity computers / elastic on-demand resource allocation
faulty node / off‐line (batch) jobs
rolling upgrade / timeout

Detecting Faults
load balancer (take it out of rotation)
single-leader replication (if the leader fails, one of the followers needs to be promoted to be the new leader)

Timeouts / suffered a temporary slowdown / load spike
Unbounded Delays (there is no upper limit on the time it may take for a packet to arrive)

Network congestion and queueing / queue them up / incoming data / network is functioning fine / is queued (buffered)
variability / jitter of network delays / maximum capacity
bounded delay (because there is no queueing, the maximum end-to-end latency of the network is fixed.)
bursty traffic / bandwidth allocation / quality of service (QoS) / admission control (rate-limiting senders)
dynamic resource partitioning / statically partitioned (reduced utilization) / multi-tenancy with dynamic resource partitioning provides better utilization (Variable delays)

Unreliable Clocks
cache entry expire / durations (the time interval between a request being sent and a response being received)
Network Time Protocol (NTP)

Monotonic clock (System.nanoTime() in Java) / Time-of-Day Clocks (System.currentTimeMillis() in Java)
Clock Synchronization and Accuracy / Clock drift / occasional spikes
Relying on Synchronized Clocks
Timestamps for ordering events / last write wins (LWW) / lagging clock / fast clock
Additional causality tracking mechanisms, such as version vectors, are needed in order to prevent violations of causality
the definition of 'recent' depends on a local time-of-day clock, which may well be incorrect.
logical clocks / physical clocks

Clock readings have a confidence interval (Google's TrueTime API)

Synchronized clocks for global snapshots
On a single-node database, a simple counter is sufficient for generating monotonically increasing transaction ID
when a database is distributed, a global, monotonically increasing transaction ID (across all partitions) is difficult to generate, because it requires coordination
timestamps (the uncertainty about clock accuracy)
clock's confidence interval as reported by the TrueTime API (deliberately waits for the length of the confidence interval before committing a read-write transaction,
                                                             so their confidence intervals do not overlap)

Process Pauses / Java Virtual Machine) have garbage collector (GC)
lease - a lock with a timeout /  periodically renew / expires

Response time guarantees / hard real-time systems
Limiting the impact of garbage collection

Knowledge, Truth, and Lies
A distributed systems are different from programs running on a single computer:
    there is no shared memory
    only message passing via an unreliable network with variable delays
    the systems may suffer from partial failures
    unreliable clocks
    processing pauses

system model (assumptions we are making about the behavior)
quorum / voting / consensus algorithms / majority of nodes
promoted / demoted / in the order of increasing fencing tokens
ZooKeeper is used as lock service / the transaction ID zxid or the node version cversion can be used as fencing token

outdated / malfunctioning / malicious attackers are interfering with the network / peer-to-peer networks
input validation, sanitization / sanitize any inputs from users, and output escaping / prevent SQL injection and cross-site scripting
protect us from vulnerabilities, security compromises, and malicious attacks
traditional mechanisms (authentication, access control, encryption, firewalls)

Synchronous model: bounded network delay, bounded process pauses, and bounded clock error / not a realistic model
Partially synchronous model: behaves like a synchronous system most of the time, but it sometimes exceeds the bounds for network delay, process pauses, and clock drift / realistic model
Asynchronous model:
Crash-stop faults:
Crash-recovery faults: stable storage preserved across crashes, while the in-memory state is assumed to be lost
Byzantine (arbitrary) faults:

For modeling real systems, the partially synchronous model with crash-recovery faults is generally the most useful model
send a packet over the network / be significantly out of sync with / jump forward or back in time

However, timeouts can't distinguish between network and node failures, and variable network delay sometimes causes a node to be falsely suspected of crashing.
there is no global variable, no shared memory, no common knowledge or any other kind of shared state between the machines.
Major decisions cannot be safely made by a single node, so we require protocols that enlist help from other nodes and try to get a quorum to agree
------------------------------------------------------------------------------------------------------------------------

Consistency and Consensus
tolerating faults / service functioning correctly / internal component is faulty
atomicity / concurrently accessing
consensus / fail over to another node / use consensus to elect a new leader / split brain

Consistency Guarantees / eventual consistency (convergence) / high concurrency
consistency models: systems with stronger guarantees may have worse performance or be less fault-tolerant than systems with weaker guarantees

distributed consistency models / hierarchy of transaction isolation levels
transaction isolation is primarily about avoiding race conditions due to concurrently executing transactions,
whereas distributed consistency is mostly about coordinating the state of replicas in the face of delays and faults.

linearizability (one of the strongest consistency models)
linearizability (also known as atomic consistency, strong consistency, immediate consistency, or external consistency)
linearizability is a recency guarantee (recency guarantee means that the value read must be the most recent or up-to-date value, and is not from a stale cache)

database replica that is lagging / query returned a stale result is a violation of linearizability
The basic idea behind linearizability is simple: to make a system appear as if there is only a single copy of the data, and all operations on it are atomic

variable network delays / atomic compare-and-set (cas) operation can be used to check the value hasn't been concurrently changed by another client
Linearizability Versus Serializability
Serializability is an isolation property of transactions, where every transaction may read and write multiple objects / executed in some serial order
Linearizability is a recency guarantee on reads and writes of a register (an individual object)
strict serializability or strong one-copy serializability (strong-1SR)

Coordination services like Apache ZooKeeper and etcd are often used to implement distributed locks and leader election
The most common approach to making a system fault-tolerant is to use replication
    Single-leader replication (potentially linearizable)
    Consensus algorithms (linearizable)
    Multi-leader replication (not linearizable)
    Leaderless replication (probably not linearizable)

CAP Theorem is sometimes presented as Consistency, Availability, Partition tolerance: pick 2 out of 3
a better way of phrasing CAP would be either Consistent or Available when Partitioned

The reason for dropping linearizability is performance, not fault tolerance.
order of writes / some sequential order / helps preserve causality
violates our intuition of cause and effect / causal dependency
snapshot isolation for transactions: consistent with causality - if the snapshot contains an answer, it must also contain the question being answered
Read skew (non-repeatable reads) means reading data in a state that violates causality

write skew demonstrated causal dependencies
causally consistent: snapshot isolation provides causal consistency

The causal order is not a total order / causality defines a partial order
Linearizability is stronger than causal consistency (Linearizability > causality consistency > eventually consistency)
monotonically increasing sequence number / odd-numbered operation and an even-numbered operation

a Lamport timestamp provide a total ordering consistent with causality: a pair of (counter, node ID)
every node and every client keeps track of the maximum counter value it has seen so far, and includes that maximum on every request.
When a node receives a request or response with a maximum counter value greater than its own counter value, it immediately increases its own counter to that maximum.

version vectors can distinguish whether two operations are concurrent or whether one is causally dependent on the other, whereas Lamport timestamps always enforce a total ordering

Total Order Broadcast (atomic broadcast - atomic messaging system that keeps all nodes in sync) / a kind of consensus algorithms / Total ordering across all partitions is possible, but requires additional coordination
Reliable delivery / Totally ordered delivery (Messages are delivered to every node in the same order)
Consensus services such as ZooKeeper and etcd actually implement total order broadcast
state machine replication / total order broadcast stronger than timestamp ordering
In ZooKeeper, this sequence number is called zxid (ZooKeeper transaction id)

sequential consistency, also known as timeline consistency, a slightly weaker guarantee than linearizability
atomic increment-and-get operation

Distributed Transactions and Consensus / get several nodes to agree on something
Leader election
Atomic commit / maintain transaction atomicity / abort / roll back / undone / discarded

two-phase commit (2PC) algorithm (the most common way of solving atomic commit)
From single-node to distributed atomic commit: a single device makes the commit atomic. However, what if multiple nodes are involved in a transaction?
Introduction to two-phase commit: Two-phase commit is an algorithm for achieving atomic transaction commit across multiple nodes
                                  commit / abort process in 2PC is split into two phases

Two-phase commit (2PC) and two-phase locking (2PL) are two very different things.
2PC provides atomic commit in a distributed database, whereas 2PL provides serializable isolation.
2PC uses a new component, a coordinator (also known as transaction manager)
in-doubt participants / prepare request / commit request in phase 2 / abort request / A system of promises
transaction ID is globally unique / checking for any conflicts or constraint violations / commit point
state is called in doubt or uncertain
Two-phase commit is called a blocking atomic commit protocol / nonblocking

three-phase commit (3PC) has been proposed
perfect failure detector

criticized for causing operational problems, killing performance
Database-internal distributed transactions / Heterogeneous distributed transactions

Read Committed: locking / take a row-level exclusive lock on any rows they modify, to prevent dirty writes
serializable isolation: two-phase locking would also have to take a shared lock on any rows read by the transaction

Recovering from coordinator failure / orphaned in-doubt transactions (coordinator cannot decide the outcome for whatever reason)
heuristic decisions / amplifying failures

Fault-Tolerant Consensus: Uniform agreement / Integrity / Validity / Termination

Limitations of Consensus algorithms
    synchronous replication / some committed data can potentially be lost on failover
    Consensus systems always require a strict majority to operate. This means you need a minimum of three nodes in order to tolerate one failure
    assume a fixed set of nodes that participate in voting / static membership algorithms / Dynamic membership extensions
    generally rely on timeouts to detect failed nodes. In environments with highly variable network delays,
    especially geographically distributed systems, it often happens that a node falsely believes the leader to have failed due to a transient network issue.
    particularly sensitive to network problems

Membership and Coordination Services
ZooKeeper or etcd are often described as 'distributed key-value stores' or 'coordination and configuration services'
ZooKeeper (distributed coordination) is modeled after Google’s Chubby lock service, implementing
    Linearizable atomic operation / lock (lease) / concurrently perform the same operation, only one of them will succeed / consensus protocol guarantees that operation is atomic & linearizable
    Total ordering of operation / fencing token / monotonically increasing transaction ID (zxid) / version number (cversion)
    Failure detection / periodically exchange heartbeats / session timeout configured to be automatically released / ZooKeeper calls these ephemeral nodes
    Change notifications / a client can find out when another client joins the cluster (based on the value it writes to ZooKeeper)

ZooKeeper is used for Service discovery to find out which IP address you need to connect to in order to reach a particular service.

linearizability: makes a database behave like a variable in a single-threaded program / has the downside of being slow, especially in environments with large network delays
causality:  weaker consistency model / can be concurrent, so the version history is like a timeline with branching and merging
consensus: needs to somehow know that another node isn't concurrently in the process

This is what happens in a single-leader database:
    Linearizable compare-and-set registers
    Atomic transaction commit
    Total order broadcast
    Locks and leases
    Membership/coordination service
    Uniqueness constraint

This is what happens in a single-leader database, three ways of handling that situation:
    Wait for the leader to recover, and accept that the system will be blocked in the meantime
    Manually fail over by getting humans to choose a new leader node and reconfigure the system to use it
    Use an algorithm to automatically choose a new leader / consensus algorithm

ZooKeeper play an important role in providing an 'outsourced' consensus, failure detection, and membership service
leaderless and multi-leader replication systems typically do not use global consensus / cope without linearizability / branching and merging version histories.
------------------------------------------------------------------------------------------------------------------------
The Lamport timestamp algorithm is a simple logical clock algorithm used to determine the order of events in a distributed computer system.

Total order broadcast: If m1 is delivered before m2 on one node, then m1 must be delivered before m2 on all nodes
                       All nodes must deliver messages in the same order. This includes a node's deliveries to itself!

Gossip protocols: Useful when broadcasting to a large number of nodes.
                  Eventually reaches all nodes (with high probability).

Eventual consistency
    Linearizability advantages:
        - Makes a distributed system behave as if it were non-distributed
        - Simple for applications to use
    Downsides:
        - Performance cost: lots of messages and waiting for responses
        - Scalability limits: leader can be a bottleneck
        - Availability problems: if you can't contact a quorum of nodes, you can't process any operations
    Eventual consistency: a weaker model than linearizability. Different trade-off choices.
------------------------------------------------------------------------------------------------------------------------
Conict-free Replicated Data Types (CRDTs)
    - Operation-based
    - State-based

Operation-based CRDTs
    Reliable broadcast may deliver updates in any order
    Recall strong eventual consistency:
        - Eventual delivery: every update made to one non-faulty replica is eventually processed by every non-faulty replica.
        - Convergence: any two replicas that have processed the same set of updates are in the same state
    CRDT algorithm implements this:
        - Reliable broadcast ensures every operation is eventually delivered to every (non-crashed) replica
        - Applying an operation is commutative: order of delivery doesn't matter

State-based CRDTs
    Merge operator must satisfy: Commutative / Associative / Idempotent
    State-based versus operation-based:
        - Op-based CRDT typically has smaller messages
        - State-based CRDT can tolerate message loss/duplication
    Not necessarily uses broadcast:
        - Can also merge concurrent updates to replicas e.g. in quorum replication, anti-entropy, .
------------------------------------------------------------------------------------------------------------------------

Google's Spanner
    A database system with millions of nodes, petabytes of data, distributed across datacenters worldwide
    Consistency properties:
        - Serializable transaction isolation
        - Linearizable reads and writes
        - Many shards, each holding a subset of the data; atomic commit of transactions across shards
Many standard techniques:
        - State machine replication (Paxos) within a shard
        - Two-phase locking for serializability
        - Two-phase commit for cross-shard atomicity
The interesting bit: read-only transactions require no locks!
