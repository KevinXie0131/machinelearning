+++Chapter 17: Proximity Service

search radius / expand the search
Functional requirements / Non-functional requirements
latitude and longitude pair

LBS: location based service
user privacy / comply with data privacy laws
the spike in traffic during peak hours

API design / Data model (schema design) / High-level design / deep dive into
search results are paginated
reviews / star rating
a new endpoint call to fetch the detailed information

Google Places API: a service that accepts HTTP requests for location data through a variety of methods
read/write ratio / read volume / write volume / infrequent operations

Geospatial indexing is a technique used in databases to efficiently store and retrieve data based on their geographic location
Geohash is a unique identifier of a specific region on the Earth. For a given location on earth, the Geohash algorithm converts its latitude and longitude into a string.

Database cluster can be used for primary-secondary setup
due to replication delay
off-peak hours
different regions and availability zones

geospatial databse such as GeoHash in Redis or PostgreSQL with PostGIS extension
Redis geospatial indexes let you store coordinates and search for them. This data structure is useful for finding nearby points within a given radius or bounding box.

Option 1: Two-dimensional search: not efficient
Option 2: Evenly divided grid: the distribution of business is not even / need more granular grids for dense areas and large grids in sparse areas
Option 3: Geohash: reduce two-dimensional longitude and latitude data into one-dimensional string ofa letters and digits / has 12 precisions (also called levels)
                   only interested in geohashes with lengths between 4 and 6 / edge cases with how the geohash boundary is handled
                   the longer a shared prefix is between two geohashes, the closer they are
                   a common solution is to fetch not only within the current grid but also from its neighbors

Option 4: Quadtree: (a tree data structure in which each internal node has exactly four children)
                   In memory data structure, not database solution. It doesn't take too much memory and easily fit in one server
                   incrementally rebuild the quadtree, a small subset of servers at a time, across the entire cluster
                   roll out a new release / Blue/green deployment
                   mitigated by setting up a business agreement / update the cache using a nightly job
                   update it on the fly

Option 4: Google S2: a library for spherical geometry / in-memory solution / maps a sphere to 1D index based on Hilbert curve

compound key of (geohash, business_id)
have a series of replicas to help with the read load
a key-value store like Redis
no locking mechanism is needed
fetch fully hydrated business information

------------------------------------------------------------------------------------------------------------------------
+++Chapter 18: Nearby Friends

reasonable assumption / constraints and assumptions
inactive friends
privacy and data laws
occasional data loss
location refresh interval
load more upon request

stateful and bi-directional WebSocket services: each client maintains a persistent WebSocket connection to one of these servers
spread out load evenly
Restful API servers: stateless HTTP servers

Redis location cache: store the most recent location data for active user / Time to Live (TTL)
Redis pub/sub server: lightweight message bus / channels, also called topics
broadcast the update to all the subscribers
Redis provides super-fast read/write operations. It supports TTL used to auto-purge inactive users from the cache.
Redis servers are easily shard based on user id
Redis pub/sub server is used as a routing layer to direct messages

can be horizontal scaled / shard by user id
at a lower scale / increase the scale
inactivity timeout period
minimize downtime
conservative estimation

service discovery: Zookeeper & etcd (A distributed, reliable key-value store for the most critical data of a distributed system)
service discovery is a small key-value store to hold configuration data

consistent hashing / hash ring
over-provisioned / operational overhead and risks
performance hotspots
the incremental load should not overwhelm any single one

nearby random person: a pool of pub/sub by geohash

WebSocket: real-time communication between clients and the servers
Redis: fast read and write of location data
Redis Pub/Sub: routing layer to direct location updates from one user to all the online friends
Redis Pub/Sub implements a real-time messaging system, where publishers, publish to a channel/topic and several clients can subscribe to that channel/topic.

------------------------------------------------------------------------------------------------------------------------
+++Chapter 19: Google Maps

OpenStreetMap
Geocoding is the process of converting addresses to geographic coordicates
Geohashing is an encoding system that encodes a geographic area into a shoet string of letters and digits

Dijkstra's or A* pathfinding algorithms
nodes(intersections) and edges(roads)

rough estimation / server throughput / GPS are batched
analyze user behavior to enable personalization / leverage the location data in near real-time
sent in batch to the server at a lower frequency

communication protocol: HTTP with the keep-alive option
CDN fetches a copy from the origin server, caches it locally and returns it to the user
CDN returns a cached copy without contacting the origin server

keep mobile data usage low / client-side caching
a fast lookup mechanism

cloud storage, Amazon S3
prioritize availability over consistency
partition kay

Kafka: message queue. A unified low-latency, high-throughput data streaming platform designed for real-time data feeds
------------------------------------------------------------------------------------------------------------------------
+++Chapter 20: Distributed Message Queue

systems are broken up into small and independent building blocks with well-defined interfaces between them
Message queues provide communication and coordic=nation for those building blocks

Benefits of message queues:
    - Decoupling: eliminate tight coupling
    - Improved scalability: more consumers are added to handle the increased traffic during peak hours
    - Increased availability: if part of system goes offline, the other continue to interact with queue
    - Better performance: make asynchronous communication easy. Don't need to wait for each other (add to a queue without waiting for response / consume messages whenever they are available)

Apache Kafka (distributed event store and stream-processing platform) / Apache RocketMQ / RabbitMQ / Apache Pulsar / Apache ActiveMQ / ZeroMQ

Kafka and Pulsar are not message queues, but event streaming platform
performant enough

design a distributed message queue with additional features, such as long data retention, repeated comsumption of messages, etc., which are typically only available on event streaming platforms
basic functionality of message queue: producers send messages to a queue, and consumers consume messages from it
other considerations include performance, message delivery semantics (at-most-once, at-least-once, exactly-once), data detention, etc.

Apache Kafka Message Delivery Semantics:
    - At-Most-Once: a message is delivered either one time only or not at all / suitable for monitoring metrics / ack = 0
    - At-Least-Once: a message can be delivered one or more times, but will never be lost. / result in duplicates / suitable for client side which has deduplication / ack = 1 or ack = all
    - Exactly-Once: a  message will always be delivered only one time. / suitable for financial related user cases (payment, accounting and trading) / downstream service doesn't support idempotency

a traditional distributed message queue doesn't retain a message once it has ben successfully delivered to a consumer
a traditional distributed message queue doesn't guarantee delivery orders
a traditional distributed message queue provides on-disk overflow capacity

Messages are measured in the range of KBs
target throughput / end-to-end latency
support a sudden surge in message volume
several orders of magnitude smaller than

producer / consumer / produce / consume / subscribe
message queue is server, and producer/consumer are clients in server/client model

Messaging models:
   - Point-to-point: consumed by only one consumer / There is no data retention in this model
   - Publish-subscribe: implemented by topics

Topics: the categories used to organize messages / each topic has a unique name
Partitions (sharding): a small subset of the messages for a topic
Offset: the position of a message in the partition
Brokers: the servers which hold the partitions
Consumer group: the consumers form a Consumer group for a partition / a set of consumers consume messages from topics together

pull data from these partitions of message queue cluster
a constraint: a single partition can only be consumed by one consumer in the same group

Coordination service: Apache Zookeeper / etcd are used to elect a a controller
send message in batches/ persist messages in even larger batches

Data storage:
   - Option 1: database: database doesn't support read-heavy and write heavy access patterns at a large scale
   - Option 2: Write-ahead-log (WAL). WAL is just a plain file where new entries are appended to an append-only log
               WAL has a pure sequential read/write access pattern. The disk performance of sequential access is good

messages are in transit
cyclic redundancy check (CRC)
routing layer: all messages sent to the routing layer are routed to the correct broker
leader/follower replicas: fault-tolerance

Buffer
   - fewer network hops mean lower latency
   - Batching buffers messages in memory and sends out larger batches in a single request. This increases throughput
The size of batch is a trade-off between throughput and latency

Push vs Pull (most choose pull model)
    push model:
        pros: low latency
        cons: consumers could be overwhelmed
    pull model
        pros: consumers control the consumption rate / can simply scale out the consumers / more suitable for aggressive batch processing
        cons: If there is no message, keeping pulling is wasting resources.

consumer re-balancing / partition dispatch plan / heartbeat

State Storage stores:
   - The mapping between partitions and consumers
   - The last consumed offsets of consumer groups for reach partition
   access pattern for consumer state:
      - Frequent read/write operations but the volume is not high
      - Data is updated frequently and is rarely deletd
      - Random read/write operations
      - Data consistency is important
   A key-value store like Zookeeper is a good choice

Metadata storage stores the configuration and properties of topics, including a number of partitions, retention period, and distribution of replicas
Zookeeper is a good choice for storing metadata (high consistency requirement)

Zookeeper offers a hierarchical kay-value store and used to provide a distributed configuration service, synchronization service, and naming registry
Zookeeper helps with the leader election of broker cluster

Replication is the solution to achieve high availability
replica distribution plan
In-sync replicas (ISR) / committed offset / fully caught up with the leader / lag time / trade-off between performance and durability
acknowledge setting:
    ACK = all: producer get acknowledge after all ISRs received message / the strongest message durability
    ACK = 1: producer get acknowledge once the leader persists message / The latency is improved by not waiting for data synchronization / occasional data loss is acceptable
    ACK = 0: producer keeps sending message without waiting for any acknowledge / lowest latency at the cost of potential data loss / good for collecting metrics or logging data since data volume is high but data loss is acceptable

data mirroring copies data across data centers
server crashes / failure recovery of the brokers / tolerate failure of the node
replicas should not be in the same node
decommissioned partition

Message filtering: consumer fetches the full set of messages and filters out unnecessary messages
                   attach a tag to metadata of each message and broker can filter message in that dimension

RocketMQ support delayed messages with specific levels of time precision
Scheduled message is similar with delayed message

Protocol: Advanced Message Queueing Protocol (AMQP) / Kafka Protocol
    - Cover all activities such as production, consumption and heartbeat
    - Effectively transport data with large volumes
    - Verify the integrity and correctness of the data
Retry consumption: send failed messages to dedicated retry topic
Historical data archive: time-based or capacity-based log retention mechanism / use HDFS or object storage to store historical data
------------------------------------------------------------------------------------------------------------------------
+++Chapter 21: Metrics Monitoring and Alerting System

Datadog / InfluxDB / New Relic / Nagios / Prometheus / Munin / Grafana / Graphite / OpenTSDB

in-house system / 1-year retention
reduce the resolution of the data for long-term storage / roll them up to 1-min resolution / raw form of data
distributed system tracing
Log monitoring: Elasticsearch, Logstash, Kibana (ELK) stack

Data collection
Data transmission
Data storage
Alerting: detect anomalies
Visualization

Data model: Metrics data recorded a a time series that contains a set of values with associated timestamps
the line protocol: common input format for monitoring software
collected at high frequency
read volume could be bursty / spiky

time-series database: OpenTSDB / MetricsDB / Timestream /  InfluxDB / Prometheus
in-memory cache / on-disk storage

feature of time-series database is efficient aggregation and analysis of a large amount of time-series data by labels, also known as tags in some databases

Metrics data / Metrics source
Metrics collector:
    Pull vs Push model:
        Pull model: pull metrics values from running applications periodically
                    Service Discovery (etcd, Zookeeper): Metrics collector needs to know the complete list of service endpoints to pull data from
                                                         configuration metadata of service endpoints from service discovery: pulling interval, IP addresses, timeout and retry parameters
                                                         metrics collector pulls metrics data via a pre-defined HTTP endpoint
                                                         metrics collector polls from endpoint changes periodically
                    A pool of metrics collector: One potential approach is to designate each collector to a range in a consistent hash ring
        Push model: collection agent installed on every server monitored
                    collection agent is a long-running software to collect metrics from the services running on the server and pushed those metrics periodically to the metrics collector
                    Aggregation: reduce the volume of data sent to the metrics collector


Scale metrics transmission (ingestion) pipeline
    metrics collector send metrics data to queueing system like Kafka, then consumers or straming processing services
    such as Apache Storm, Flink, and Spark process the push data to the time-series database

Scale Kafka
    - Partition metrics data by metrc names, so consumers can aggregate data by metrics names
    - Further partition metrics data with tags/labels

Aggregations:
    Collection agent: only support simple aggregation logic, like aggregate a counter
    Ingestion pipeline: stream processing engines like Flink / only calculated result is written to database / downside is that we no longer store raw data
    Query side: query speed might be slow / For a well-chosen time-series database, there is no need to add own caching

Data encoding and compression can significantly reduce the size of the data, like Double-delta Encoding
Down-sampling is the processing of converting high0resolution data to low-resolution to reduce overall disk usage
Cold storage is the storage of inactive data that is rarely used

Build vs Buy / available off-the-shelf alerting systems
Visualization system: Grafana
------------------------------------------------------------------------------------------------------------------------
+++Chapter 22: Ad Click Event Aggregation

One core benefit of online advertising is its measurably, as quantified by real-time data
digital advertising has a core process called Real-Time Bidding(RTB) / the speed of RTB is less than 1 second

Publisher -> Supply Side Platform -> Ad Exchange <- Demand Side Platform <- Advertiser

Data accuracy / click-through rate (CTR) / conversion rate (CVR) / targeted audience group
parameters should be configurable /  end-to-end latency should be a few minutes

Query API design: run query against the aggregation service
    API 1: Aggregate the number of clicks of ad_id in the lat M minutes
    API 2: Return top N most clicked ad_ids in the last M minutes

Data model:
   Raw data: Data is scattered on different application servers / backup data
   Aggregated (derived) data: add additional field call filed_id / Records are grouped by filed_id / active data

unbounded data stream / aggregated result
Asynchronous processing: adopt a message queue, Kafka to decouple producers and consumers / producers and consumers can scaled independently

the second message queue like Kafka to achieve end-to-end exactly-once semantics (atomic commit)

Aggregation service: MapReduce framework is a good solution to aggregate ad click events / Directed acyclic graph (DAG)
map > aggregate -> reduce -> top 10 aggregation

data filtering: star schema / the filtering fields are called dimensions

Streaming (near real-time system / Flink / infinite stream) vs Batching (offline system / MapReduce / bounded input with finite size)
lambda architecture: In addition to the batch layer and speed layers, Lambda architecture also includes a data serving layer for responding to user queries.
kappa architecture

Aggregation window / 4 types of window functions:
    - tumbling/fixed window: time is partitioned into same-length, non-overlapping chunks
    - hopping window: a windows slides across the data stream, according to a specific interval / get the top N most clicked ads during the last M minutes
    - sliding window
    - session window

data deduplication: malicious intent is handled by ad fraud/rish control components / server outage / upstream service hasn't received acknowledge, stream event might be sent again
A distributed transaction is a transaction that works across several nodes
To achieve exactly-once in Kafka, offset can be save in HDFS/S3 after acknowledge is back from downstream

during off-peak hours to minimize the impact / pre-allocate enough partitions in advance
topic physical sharding: Slicing data to different topics can help increase system throughput. With fewer consumers for a single topic,
                         the time to re-balance consumer groups is reduced. However, it introduces extra complexity and maintenance costs

How to increase the throughput of the aggregation service:
    Option 1: Allocate events with different ad_ids to different threads
    Option 2: Deploy aggregation service nodes on resource providers like Apache Hadoop YARN

Hotspot issue: mitigated by allocating more aggregation nodes to process popular ads

Fault-tolerant: save the 'System status' like upstream offset to a snapshot and recover from the latest saved status
Failover process: if one aggregation service node fails, we bring up a new node and recover data from the latest snapshot
Reconcile with / Reconciliation: compare different sets of data in order to ensure data integrity / a batch job
------------------------------------------------------------------------------------------------------------------------
+++Chapter 23: Hotel Reservation System

the scale of the system / overbooking / within the scope / out of the scope
average transaction per second (TPS)
QPD distribution / reach the final step / drop off the flow / walk backwards along the funnel

not technically challenging
used as idempotency key to prevent double booking
a few oder of magnitudes higher than

relational database works well with ready-heady and write lee frequently workflows
NoSQL databases are generally optimized for writes aand relational database works well with ready-heavy workflow

the relationship between different entities is stable
Reservation status: pending / paid / refunded / canceled / rejected

standard room / king-size room / queen-size room
design is modeled with microservice architecture / high-level design diagram

Public API Gateway: rate limiting / authentication / configured to direct | route requests to specific service based on endpoints
Internal APIs: authorized staff / further protected by VPN
inter-service communication often employs a modern and high-performance remote procedure call (RPC) framework like gRPC

inventory / composite primary key / a scheduled daily job to pre-populate the inventory data
set up database replication across multiple regions or availability zones
history can be achieved and moved to cold storage

Database sharding: hotel_id is a good sharding key. the data can be sharded by hash(hotel_id)%number_of_servers

concurrency issue:
    - the same user books multiple times:
        + client-side implementation: not very reliable
        + idempotent APIs: add an idempotency key in the reservation API request
                           use the idempotency kay (reservation_id) to avoid double reservation issue (unique constraint violation)
                           The unique reservation_id is generated by a globally unique ID generator
    - multiple users try to book the same room at the same time
        + locking mechanism: pessimistic locking (pessimistic concurrency control):
                                 > prevent simultaneous updates by placing a lock on a record as soon as one user starts to update it
                                 > other users have to wait until the first user has released the clock
                                 > Begin Transaction / Commit Transaction / Rollback Transaction
                                 > Pros: Easy to implement and avoid conflict by serializing updates
                                 > Cons: deadlocks may occur when multiple resources are locked / This approach is not stable / So do not recommend
                             optimistic locking (optimistic concurrency control):
                                 > version number (better option because server clock cannot be accurate over time)
                                      the next version number should exceed the current version number by 1 / Transaction aborts if the validation fails
                                      Pros: prevent application from editing stale data
                                             no need to lock database resource. up to application to handle logic
                                      Cons: performance is port when data contention is heavy
                                 > timestamp
                             database constraints: Add a Constraint of CHECK
                                                   Easy to implement and works well when data contention is minimal
                                                   database constraint cannot be version-controlled easily by code
                                                   not all databases support constraints

Database sharding: to split data into multiple databases so that each of them only contains a portion of data
Inventory Caching: Redis is a good choice because TTL and Least Recently Used (LRU) cache eviction policy help us male optimal use of memory / as a precaution / the source of true for the inventory data
The volume of read operations is an order of magnitude higher than write operations

How to maintain consistency between cache and database
    - propagated to the cache asynchronously
    - Change Data Capture (CDC) / Debezium
    - final inventory validation check / some else just booked the last room

Data consistency among services: In microservice architecture, each service has its own database. one logically atomic operation can span multiple services
                                 there is only one happy path, and many failure case could cause data inconsistency
    - Two-phase commit (2PC)
        guarantee atomic transaction commit across multiple nodes / blocking protocol / not performant
    - SAGA design pattern
        a way to manage data consistency across microservices in distributed transaction scenarios
        a sequence of local transactions
        consist of multiple steps and rely on eventual consistency
------------------------------------------------------------------------------------------------------------------------
+++Chapter 24: Distributed Email Service

------------------------------------------------------------------------------------------------------------------------
+++Chapter 25: S3-like Object Storage

------------------------------------------------------------------------------------------------------------------------
+++Chapter 26: Real-time Gaming Leaderboard

------------------------------------------------------------------------------------------------------------------------
+++Chapter 27: Payment System

------------------------------------------------------------------------------------------------------------------------
+++Chapter 28: Digital Wallet

------------------------------------------------------------------------------------------------------------------------
+++Chapter 28: Stock Exchange
