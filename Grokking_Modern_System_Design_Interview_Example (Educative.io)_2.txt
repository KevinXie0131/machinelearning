Instagram - A perfect example of how different building blocks combine to build a scalable and performant system

Users can add a caption for each post and utilize hashtags or location-based geotags to index them and make them searchable within the application.
A user’s Instagram posts display in their followers’ feeds

We can compromise a little on consistency. It is acceptable if the content (photos or videos) takes time to show in followers’ feeds located in a distant region.
system is read-heavy because service users spend substantially more time browsing the feeds of others than creating and posting new content.
efficient storage management should be a primary consideration

the ratio of readers to writers is 100:1.
We can use compression to reduce the media size substantially.
A task scheduler schedules the events on the database such as removing the entries whose time to live exceeds the limit.

The POST method is used to post photos/videos to the server from the user through the /postMedia API.

data is inherently relational, and we need an order for the data (posts should appear in chronological order) and no data loss even in case of failures (data durability).
benefit from relational queries like fetching the followers or images based on a user ID

a unidirectional relationship
We'll store the photos and videos in a blob store (like S3) and save the path of the photo or video in the table as it is efficient to save larger data in a distributed storage.

he loosely structured data like timeline generation is usually stored in No-SQL, while relational data is saved in SQL-based storage.

It is efficient if we separate the write (uploads) and read services.
Generate a timeline:
    - The pull approach:
        > this approach is slow to respond as we generate a timeline every time the user opens Instagram.
        > can substantially reduce user-perceived latency by generating the timeline offline.
        > Instagram is a read-heavy system. So, the calls we make to fetch the recent posts from every follower will usually return nothing.
    - The push approach: every user is responsible for pushing the content they posted to the people’s timelines who are following them
        > Consider an account that belongs to a celebrity. So we will push the links of the photo/video to millions users, which is inefficient.
    - Hybrid approach
        > Push-based users: The users who have a followers count of hundreds or thousands.
        > Pull-based users: The users who are celebrities and have followers count of a hundred thousand or millions.

We can set it to 24 hours, and the task scheduler deletes the entries whose time exceeds the 24 hours limit.
------------------------------------------------------------------------------------------------------------------------
TinyURL - Encoding IDs in the base-58 system for generating unique short URLs

URL shortening is a service that produces short aliases for long URLs, commonly referred to as short links.
Advantages:
    - convenient to use
    - visually professional, engaging and facilitate a higher degree of sharing possibilities.
    - less error-prone while typing.
    - require smaller storage space
Disadvantages:
    - lose the originality of our brand
    - the possibility of it getting shut down and wiping all our shortened URLs will always be there.
    - Our business brand image depends on the trustworthiness of a URL shortening service.
      the best custom URLs are already taken by the time we start generating short URLs.

TinyURL-like URL shortening service / generate a unique shorter alias of the given URL / generate custom short links for their URLs
Redirection: Given a short link, our system should be able to redirect the user to the original URL.
Expiry time: There must be a default expiration time for the short links

readable, distinguishable, and typeable.
Unpredictability: From a security standpoint, the short links generated by our system should be highly unpredictable.
                  not serially produced, eliminating the possibility of someone guessing
                  secret URLs / risking the secrecy of the private URLs / compromise the privacy of a user's data, making our system less secure

entry requires 500 Bytes of database storage.
Each entry will have a maximum of five years of expiry time, unless explicitly deleted.
We need memory estimates in case we want to cache some of the frequently accessed URL redirection requests.
Let's assume a split of 80-20 in the incoming requests. 20 percent of redirection requests generate 80 percent of the traffic.

Rate limiters will be used to avoid system exploitation.
A Base-58 encoder to transform the sequencer's numeric output to a more readable and usable alphanumeric form.

api_dev_key: A registered user account's unique identifier.
             This is useful in tracking a user's activity and allows the system to control the associated services accordingly.

Database: horizontally scalable
Additionally, the stored records will have no relationships among themselves other than linking the URL-creating user's details,
    so we don't need structured storage for record-keeping.
    our system will be read-heavy, NoSQL is a suitable choice for storing data.

MongoDB is a good choice:
    - It uses leader-follower protocol, making it possible to use replicas for heavy reading.
    - MongoDB ensures atomicity in concurrent write operations and avoids collisions by returning duplicate-key errors for record-duplication issues.
    - MongoDB provides a higher read throughput as we can either read from the leader replica or follower replicas. The write operations have to pass through the leader replica.
      It ensures our system's availability for reading-intensive tasks even in cases where the leader dies.

Short URL generator:
    - A sequencer to generate unique IDs: generate 64-bit unique numeric IDs
    - A Base-58 encoder to enhance the readability of the short URL: requires 64-bit alphanumeric short URLs in base-58
                                                                     convert the numeric (base-10) IDs to alphanumeric (base-58)
                                                                     a base-10 for the base-58 encoder
Other building blocks:
   - load balancers: Global Server Load Balancing (GSLB)
   - cache: Memcached is the best choice for a cache solution (a simple, horizontally scalable cache system with minimal data structure requirements)
            global caching layer will result in higher latency.
   - rate limiters: Limiting each user's quota is preferable for adding a security layer to our system.
                    by uniquely identifying users through their unique api_dev_key (fixed window counter algorithm)
                    protect the system against DoS attacks
                    ensure a good and smooth traffic influx and mitigate the exploitation of system resources.

Solution: An simple way of achieving this functionality is to introduce a unique character in the short URL. This special character will act as an indicator for the exact data center.
Example: Let's assume that the short URL that needs redirection is service.com/x/short123/, where x indicates the data center containing this record.

Base-64 is the most common encoding for alphanumeric strings' generation.
   However, there are some inherent issues with sticking to the base-64 for this design problem:
   the generated short URL might have readability issues because of look-alike characters.
   Characters like O (capital o) and 0 (zero), I (capital I), and l (lower case L) can be confused
   while characters like + and / should be avoided because of other system-dependent encodings.

Converting base-10 to base-58: modulus function
Base-10 = 2468135791013 -> Base-58 = [1] [6] [48] [20] [41] [4] [6] [17] -> Base-58 = 27qMi57J

Both the base-10 numeric IDs and base-64 alphanumeric IDs have 64-bits

The output of this short URL generator depends on the design-imposed limitations, as given below:
   - The generated short URL should contain alphanumeric characters.
   - None of the characters should look alike.
   - The minimum default length of the generated short URL should be six characters.

Maximum digits: The calculations above show that the maximum digits in the sequencer generated ID will be 20 and consequently, the maximum number of characters in the encoded short URL will be 11.  
Starting range: select the sequencer IDs to start from at least 10 digits, i.e., 1 Billion.

We can use the range below the ten digits sequencer IDs for custom short links for users with premium memberships. It will ensure two benefits:
   - Utilization of the blocked range of IDs
   - Less than six characters short URLs
Our system doesn't ensure a guaranteed custom short link generation, as some other premium member might have claimed the requested custom short URL.

However, if we partition our database based on a predefined range, it might lead to imbalanced partitions due to the variable distribution of URLs in each range.
   An example of this could be the distribution based on the first letter of the URL.

Scaling a traditional relational database horizontally is a daunting process and poses challenges to meeting our scalability requirements.
We want to scale and automatically distribute our system's data across multiple servers. For this requirement, a NoSQL database would best serve our purpose.

Readability:
   - Removal of look-alike characters: Distinguishable characters like 0 (zero), O (capital o), I (capital i), and l (lower case L) are eliminated
   - Removal of non-alphanumeric characters: Non-alphanumeric characters like + (plus) and / (slash) are also eliminated to only have alphanumeric characters in short URLs.
Unpredictability:
   - Randomly selecting and associating an ID to each request, from the pool of unused and readily available unique IDs.
------------------------------------------------------------------------------------------------------------------------
Web crawler - Detection, identification, and resolution of Web crawler traps

A web crawler is an Internet bot that systematically scours the world wide web (WWW) for content, starting its operation from a pool of seed URLs
Stored URLs that serve as a starting point for a crawler.

crawling / storing (extract and store the content of a URL in a blob store / indexing and ranking)
Scheduling (crawling is a repeated process, the system should have regular scheduling to update its blob stores' records)

The additional utilities of a web crawler are as follows:
   - Web pages testing
   - Web page monitoring
   - Site mirroring
   - Copyright infringement check
The output of the crawling process is the data that's the input for the subsequent processing phases:
    data cleaning / indexing / page relevance using algorithms like page ranks / analytics.

crawler traps include links with query parameters, internal links redirection, links holding infinite calendar pages, links for dynamic content generation, and links containing cyclic directories.
There are two possible ways to create or gather seed URLs:
    - manually create them
    - scan the IP addresses for the presence of web servers
There are multiple approaches to selecting seed URLs:
    - Location-based:
    - Category-based: Depending on the type of content
    - Popularity-based: groups the seed URLs based on hot topics in a specific area

Scalability: The system should inherently be distributed and multithreaded
Extensibility: be extensible for different network communication protocols, able to add multiple modules to process, and store various file formats.
Consistency: Since our system involves multiple crawling workers, having data consistency among all of them is necessary.
Performance: The system should be smart enough to limit its crawling to a domain, either by time spent or by the count of the visited URLs of that domain.
             This process is called self-throttling.
             host a robot.txt file, which communicates domain-specified limitations to the crawler.
Improved user interface - customized scheduling

the average size of a webpage content is 2070KB (2.07MB)
metadata: It consists of a webpage title and description of the web page showing its purpose.

Traversal time: average HTTP traversal per webpage is 60 ms
support multi-worker architecture and divide the tasks among multiple workers running on different servers

Components:
   - Scheduler: a priority queue (URL frontier,  priority | updates frequency)
                a relational database (user's added URLs / crawler's extracted URLs)
        2.048 GB is a reasonable amount of space for a queue.
        However, a centralized queue has limited read/write bandwidth and is a single point of failure.
        Therefore, having a sub-queue for each worker will be the best approach.

        another solution can be to have separate queues for different priorities. We can then dequeue from these queues based on the priorities assigned to them.
   - DNS resolver: Since DNS lookup is a time-consuming process, a better approach is to create a customized DNS resolver
                   and cache frequently used IP addresses within their time-to-live because they're bound to change after their time-to-live.
   - HTML fetcher: HTML fetcher establishes a network communication connection between the crawler and the web hosts.
                   fetcher initiates communication with the server that’s hosting the URL(s).
                   downloads the file content based on the underlying communication protocol.
   - Service host: manages the crawling operation among the workers.
                   This component acts as the brain of the crawler and is composed of worker instances.
                       > handles the multi-worker architecture of the crawling operation.
                       > Each worker is responsible for acquiring the DNS resolutions of the incoming URLs from the DNS resolver.
                       > Each worker acts as a gateway between the scheduler and the HTML fetcher by sending the necessary DNS resolution information to the HTML fetcher for communication initiation.
   - Extractor: extracts the embedded URLs and the document from the web page.
                the next step is to extract two things from the webpage: URLs and the content
                The extractor sends the extracted URLs directly and the content with the document input stream (DIS) to the duplicate eliminator.
                Once it's verified that the duplicates are absent in the data stores, the extractor sends the URLs to the task scheduler that contains the URL frontier and stores the content in blob storage for indexing purposes.
   - Duplicate eliminator: performs dedup testing on the incoming URLs and the documents.
                           perform a dedup test to eliminate the risk of exploiting resources by storing and processing the same content twice.
                           The duplicate eliminator calculates the checksum value of each extracted URL and compares it against the URLs checksum data store.
                              If found, it discards the extracted URL. Otherwise, it adds a new entry to the database with the calculated checksum value.
                           use Redis as our cache
   - Blob store: Since a web crawler is the backbone of a search engine, storing and indexing the fetched content and relevant metadata is immensely important
                 The design needs to have a distributed storage,

use DFS when we want to utilize a website' persistent connection to traverse all the web pages on that specific domain.
   This saves time as it helps us avoid reconnecting with the same website repeatedly in case the session expires.

Workflow:
   - Assignment to a worker: Servie host loads a URL from the priority queue to te avaible worker
   - DNS resolution: DNS resolution of the URL
   - Communication initiation by the HTML fetcher: HTTP connection initiation for HTML fetching
   - Content extraction
   - Dedup testing: Placement of document in DIS by the extractor
                    Dedup testing of the extracted of URLs/extracted document
   - Content storing: informs the extractor about the dedup results
                      Saves the newly explored document to the blob store
   - Re-crawling: Send the newly explored URL to the scheduler
                  Enqueueing of the new URLS and recrawling continues

Design improvements:
   - HTML Fetcher: easily extend our design to incorporate other communication protocols like File Transfer Protocol (FTP)
   - Extractor: Since we use a blob store for content storage, storing the newly-extracted content comprising text, images, and videos won't be a problem.
There are several ways to achieve this multi-worker architecture for our system:
   - Domain level log: best-suited for achieving reverse URL indexing
   - Range division:
   - Per URL crawling:
Crawler traps: a URL or a set of URLs that cause indefinite crawler resource exhaustion.
   - Classification: web crawler traps are the result of poor website structuring
                     URLs with query parameters / URLs with internal links / URLs with infinite calendar pages /
                     URLs for the dynamic content generation / URLs with repeated/cyclic directories
   - Identification: Analyzing the URL scheme / Analyzing the total number of web pages against a domain
Solution:
   - The crawler must implement an application-layer logic to counter the crawler traps.
   - robots.txt: This file contains the dos and don'ts for a crawler
                 Another essential component of this document is the revisit frequency instructions for the crawler (Robots Exclusion Protocol)
   - the crawler needs to be polite enough to limit its crawling at a specific domain (Time to First Byte (TTFB))
------------------------------------------------------------------------------------------------------------------------
WhatsApp - Message management for offline users

WhatsApp is an important messaging application
keep all that data secure
Functional requirements:
   - Conversation: support one-on-one and group conversations
   - Acknowledgment: support message delivery acknowledgment, such as sent, delivered, and read
   - Sharing: support sharing of media files, such as images, videos, and audio
   - Chat storage: support the persistent storage of chat messages when a user is offline until the successful delivery of messages
   - Push notifications: be able to notify offline users of new messages once their status becomes online.

Security: The system must be secure via end-to-end encryption
Moreover, the WhatsApp servers keep the messages only for 30 days.

the high-level design consists of a chat server responsible for communication between the sender and the receiver:
   - User A and user B create a communication channel with the chat server.
   - Upon receiving the message, the chat server acknowledges back to user
   - stores the message in the database if the receiver’s status is offline.
   - The chat server notifies user A that the message has been successfully delivered.
   - Hold the message on the server in a transient storage until receiver gets back online
   - Messages are deleted from the database once delivered

Generally, the sender's and receiver's IDs are their phone numbers.
he maximum file size for media that can be uploaded is 16 MB, while the limit is 100 MB for a document.

Connection with a WebSocket server: Two users are connected via WebSocket handlers
   - each active device is connected with a WebSocket server via WebSocket protocol.
   - A WebSocket server keeps the connection open with all the active (online) users.
   - The mapping between servers, ports, and users is stored in the WebSocket manager that resides on top of a cluster of the data store.
     In this case, that's Redis.

polling is resource intensive and causes latency, but WebSocket maintains a persistent connection between the client and a server.
   This protocol transfers data to the client immediately whenever it becomes available.
   It provides a bidirectional connection used as a common solution to send asynchronous updates from a server to a client.

Send or receive messages: WebSocket communicates with message service on top of Mnesia database cluster
   - The WebSocket manager is responsible for maintaining a mapping between an active user and a port assigned to the user.
     Whenever a user is connected to another WebSocket server, this information will be updated in the data store.
   - Message service is a repository of messages on top of the Mnesia database cluster (WhatsApp uses Erlang-based distributed DBMS called Mnesia)
   - user A's WebSocket server has the information that user B is connected with its own WebSocket server.
     The communication between user A and user B gets started via their WebSocket servers.
   - Both users (sender and receiver) communicate with the WebSocket manager to find each other's WebSocket server.
   - WebSocket server caches the following information:
        > If both users are connected to the same server, the call to the WebSocket manager is avoided.
        > It caches information of recent conversations about which user is connected to which WebSocket server.
        > WebSocket manager, in turn, invalidates the data in the cache used by the WebSocket servers, and the updated data is sent to the corresponding cache.
          So, the information in the cache will remain there until it receives an invalidate signal from the WebSocket manager.

Send or receive media files: Sending media files via the asset service
   - asset service is responsible for sending and receiving media files
   - The media file is compressed and encrypted on the device side
   - store the file on blob storage
   - maintains a hash for each file to avoid duplication of content on the blob storage.
   - The content is loaded onto a CDN if the asset service receives a large number of requests for some particular content.

Support for group messages:
   - WebSocket servers don’t keep track of groups because they only track active users.
   - For group messages, the following three main components are responsible for delivering messages to each user in a group:
      > Group message handler: communicates with the group service to retrieve data of Group/A users.
      > Group message service: keeps all information about users in each group in the system
         - This service resides on top of the MySQL database cluster, with multiple secondary replicas distributed geographically.
         - A Redis cache server also exists to cache data from the MySQL servers.
      > Kafka
        - each user in a group subscribes to the relevant topic (a group with an associated messaging queue).
        - The messages are then delivered in a fanout messaging pattern

device identity key
   - each device identity key is stored against the user's account on the WhatsApp server
   - When the WhatsApp server receives a message from a user, it transmits messages multiple times to each device linked with a user's account.
   - Similarly, each device used by a user has its own set of encryption keys.

Low latency: minimize the latency of the system at various levels
   - geographically distributed WebSocket servers and the cache associated with them.
   - use Redis cache clusters on top of MySQL database clusters.
   - use CDNs for frequently sharing documents and media content.
Consistency: Provide unique IDs to messages using Sequencer or other mechanisms
             The system also provides high consistency in messages with the help of a FIFO messaging queue with strict ordering.
Availability: have enough WebSocket servers and replicate data across multiple servers.
Security: provides an end-to-end encryption mechanism
Scalability: WhatsApp can handle around 10 million connections per server

two major trade-offs exist in the proposed WhatsApp design:
   - There's a trade-off between consistency and availability.
       > In WhatsApp, the order of messages sent or received by a user is essential.
         Therefore, we should prioritize consistency rather than availability.
   - There's a trade-off between latency and security.
       > End-to-end encryption causes a delay in processing, which has an impact on latency
       > communication involves multimedia. Encrypting them in near real-time on the sender device and decrypting on the receiver side can be taxing for the devices, causing latency.
----------------------------------------------------------------------------------------------------------------------
Typeahead - The usage of an efficient trie data structure to provide suggestions

Typeahead suggestion, also referred to as the autocomplete feature, enables users to search for a known and frequently searched query.
based on the user's search history, the current context of the search, and trending content across different users and regions
Frequently searched queries always appear at the top of the suggestion list.

an efficient tree data structure called trie that's used to store search prefixes / further optimized to reduce the tree traversal time.
two main components, the suggestions service and the assembler

Low latency: The latency shouldn't exceed 200 ms.
             A study suggests that the average time between two keystrokes is 160 milliseconds
             So, our time-budget of suggestions should be greater than 160 ms to give a real-time response.

Google receives more than 3.5 billion searches every day
1 billion = 1 GB to store
Let's assume that a single server can handle 8,000 queries per second

Our proposed system should do the following:
   - Provide suggestions based on the search history of the user.
   - Store all the new and trending queries in the database to include them in the list of suggestions

suggestions service: obtains the top ten suggestions from the cache, Redis, and returns them as a response to the client.
                     The top ten popular queries are returned from the distributed cache, Redis.
assembler: collects the user searches, applies some analytics to rank the searches, and stores them in a NoSQL database that's distributed across several nodes.
           creating and updating tries after a certain configurable amount of time.
           The assembler consists of the following different services:
               - Collection service: collects the log that consists of phrases, time, and other metadata and dumps it in a database
                                     Hadoop Distributed File System (HDFS) is considered a suitable storage system for storing this raw data.
               - Aggregator: retrieves the data from the HDFS and distributes it to different workers.
                             Generally, the MapReducer is responsible for aggregating the frequency of the prefixes over a given interval of time, and the frequency is updated periodically in the associated Cassandra database.
                             Cassandra is suitable for this purpose because it can store large amounts of data in a tabular format.
               - Trie builder: creating or updating tries based on the aggregated data in the Cassandra database.
                               It stores these new and updated tries on their respective shards in the trie database via ZooKeeper.
                               NoSQL document databases such as MongoDB are suitable for storing these tries.

load balancers: distribute the incoming requests evenly.
application servers: entry points for clients so that they can forward requests to the appropriate microservices.
web servers encapsulate the internal system architecture and provide other services, such as authentication, monitoring, request shaping, management, and more.

API design:
   getSuggestions(prefix)
   addToDatabase(query): adds a trending query to the database via an assembler if the query has already been searched and has crossed a certain threshold.

update the query asynchronously using AJAX.
It allows web pages to exchange a small amount of data, as in the typeahead suggestion system, with the server without interfering with the display and behaviors of the existing web page.

The trie data structure:
   A trie is a tree-like data structure for storing phrases, with each tree node storing a character in the phrase in order.

Track the top searches: Since our system keeps track of the top searches and returns the top suggestion,
                        we store the number of times each term is searched in the trie node.

The trie can combine nodes as one where only a single branch exists, which reduces the depth of the tree. This also reduces the traversal time, which in turn increases the efficiency

One way to reduce the trie traversal time is to pre-compute and save the top ten (or any number of our choosing) suggestions for every prefix in the node.
    The system will have precomputed, sorted, and stored the solution to the prefix
    However, this approach requires extra space to save precomputed results.

Trie partitioning:
    - A good solution is to split the trie into multiple tries for a better user experience.
    - It should be noted that this simple technique doesn't always balance the load equally because some prefixes have many more words while others have fewer
we use a cluster manager like ZooKeeper to store the mapping between clusters.

Update the trie: This issue can be resolved by updating the trie offline after a specific interval.
   - To update the trie offline, we log the queries and their frequency in a hash table and aggregate the data at regular intervals.
     After a specific amount of time, the trie is updated with the aggregated information.
   - We can put up a MapReduce (MR) job to process all of the logging data regularly, let’s say every 15 minutes.
    These MR services calculate the frequency of all the searched phrases in the previous 15 minutes and dump the results into a hash table in a database like Cassandra.
     After that, we may further update the trie with the new data.
   - Another way is to have one primary copy and several secondary copies of the trie.
     While the main copy is used to answer the queries, we may update the secondary copy.
     We may also make the secondary our main copy once the upgrade is complete.
     We can then upgrade our previous primary, which will then be able to serve the traffic as well.

We can minimize the latency with the following options:
   - Reduce the depth of the tree, which reduces the overall traversal time.
   - Update the trie offline, which means that the time taken by the update operation isn't on the clients' critical path.
   - Use geographically distributed application and database servers. This way, the service is provided near the user, which also reduces any communication delays and aids in reducing latency.
   - Use Redis and Cassandra cache clusters on top of NoSQL database clusters.
   - Appropriately partition tries, which leads to a proper distribution of the load and results in better performance.
Fault tolerance: Since the replication and partitioning of the trees are provided, the system operates with high resilience.
Scalability: Since our proposed system is flexible, more servers can be added or removed as the load increases.
             the number of partitions or shards of the trees is increased accordingly.

Clients can save a local copy of the recent history of suggestions. The rate of reuse of recent history in the suggestions list is relatively high.
One of the most crucial elements is establishing a connection with the server as soon as possible.
   Usually, the connection is established with the server via a WebSocket protocol.
------------------------------------------------------------------------------------------------------------------------
Google Docs - Concurrency management for simultaneous writes, using techniques like operational transformation (OT) and Conflict-free Replicated Data Type (CRDT)

Problems arising when there's no collaborative document editing service
use an online collaborative document editing service like Google Docs

advantages:
   - Users can review and comment on a document while it's being edited.
   - There are no special hardware specifications required to get the latest features. A machine that can run a browser will suffice.
   - It's possible to work from any location.
   - Unlike local desktop editors, users can view long-term document history and restore an older version if need be.
   - The service is free of cost.
Etherpad, Microsoft Office 365, Slite

designed in two ways:
   - It could be designed as a centralized facility using client-server architecture to provide document editing service to all users.
   - It could be designed using peer-to-peer technology to collaborate on a single document.

Document collaboration: Multiple users should be able to edit a document simultaneously
Conflict resolution: Online document editing services have to resolve conflicts between users editing the same portion of a document
Suggestions: The user should get suggestions about completing frequently used words, phrases, and keywords in a document, as well as suggestions about fixing grammatical mistakes.
View count: see the view count of the document.
History: see history of collaboration on the document.

Consistency: thereby enabling a consistent view of the document.
             At the same time, users in different regions should see the updated state of the document.
             Maintaining consistency is important for users connected to both the same and different zones.
Availability: show robustness against failures





Concurrency in Collaborative Editing:










------------------------------------------------------------------------------------------------------------------------
Introduction to Distributed System Failures
The following two factors contribute to failures:
   - Diverse users: Most services have a vibrant user community, and as their needs evolve, so do the software products.
   - Complex systems: the sum of system components is more complex than the individual pieces.

Types of failure in distributed systems:
   - System failure:
   - Method failure: Such failures suspend the working of distributed systems. It may also make the system execute the processes incorrectly or enter a deadlock state.
   - Communication medium failure:
   - Secondary storage failure:

It's preferred to have a graceful degradation so that only a small portion of users are impacted for a short time.
provide resilience so that if one part fails, the rest can still operate.
experienced a global outage
affecting its other affiliates
a faulty configuration
Pitfalls of automation
Cascading failures can arise.
new cluster provisioning, existing cluster scaling, and task de-provisioning
had a ripple effect on thousands of third-party online services
