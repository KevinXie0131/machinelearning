building blocks
by some order of magnitude / increases by a factor of ten or more / linearly scale with increasing demands
use off-the-shelf components
strict consistency / strict consistency / durability target / privacy and regulatory requirements
handle ten times more load / be bogged down

Remote procedure calls (RPCs): an interprocess communication protocol / RPC spans the transport and application layers
The responsibilities of RPC runtime also include retransmission, acknowledgment, and encryption
The RPC method is similar to calling a local procedure, except that the called procedure is usually executed in a different process and on a different computer.
------------------------------------------------------------------------------------------------------------------------
Consistency Models:
    Eventual consistency (Weakest consistency) -> Causal consistency -> Sequential consistency -> Strict consistency / linearizability (Strongest consistency)

1. Eventual consistency ensures high availability
2. Causal consistency works by categorizing operations into dependent operations (causally-related operations) and independent operations / cause-and-effect relationship
3. Sequential consistency preserves the ordering specified by each client's program.
4. Strict consistency is the strongest consistency model. synchronous replication is one of the ingredients for achieving strong consistency, though it in itself is not sufficient. We might need consensus algorithms such as Paxos and Raft to achieve strong consistency.
   Linearizability affects the system's availability, which is why it's not always used. Applications with strong consistency requirements use techniques like quorum-based replication to increase the system's availability.

ACID: Atomicity, Consistency, Isolation, and Durability
CAP theorem: Consistency, Availability, and Partition Tolerance
------------------------------------------------------------------------------------------------------------------------
Failure Models:
Fail-stop (Easy to deal with) -> Crash -> Omission failures -> Temporal failures -> Byzantine failures  (Hard to deal with)

Fault tolerance techniques:
    Replication: One of the most widely-used techniques is replication-based fault tolerance
    Checkpointing: a technique that saves the system’s state in stable storage when the system state is consistent
                   When a failure occurs in the system, we can get the last computed data from the previous checkpoint and start working from there.

Application servers primarily provide dynamic content, whereas web servers mostly serve static content to the client, which is mostly a web browser.
------------------------------------------------------------------------------------------------------------------------
commodity servers
a coarse-grained estimation / reasonable upper bounds
incoming data / outgoing data
bandwidth is measured in bits per second

To mitigate this issue, each cached record comes with an expiration time called time-to-live (TTL)

Algorithms of load balancers
    - Round-robin scheduling: a repeating sequential manner
    - Weighted round-robin
    - Least connections
    - Least response time
    - IP hash
    - URL hash
------------------------------------------------------------------------------------------------------------------------
anomalies (like dirty reads, dirty writes, read skew, lost updates, write skew, and phantom reads)
semi-structured and unstructured data / document databases are structureless

NoSQL:
    - Key-value database: Amazon DynamoDB, Redis, and Memcached DB
                          Primary key = Partition key + Sort key
    - Document database: MongoDB and Google Cloud Firestore
                         XML, JSON, BSON / composed of a hierarchical tree data structure
    - Graph database: Neo4J, OrientDB, and InfiniteGraph
    - Columnar database: Cassandra, HBase, Hypertable, and Amazon SimpleDB
                         store data in columns instead of rows
                         efficient for a large number of aggregation and data analytics queries

Drawbacks of NoSQL databases:
    - Lack of standardization
    - Consistency
      We won’t have strong data integrity, like primary and referential integrities in a relational database
      Data might not be strongly consistent but slowly converging using a weak model like eventual consistency

Replication:
   - Synchronous replication
   - Asynchronous replication
Data replication models:
   - Single leader or primary-secondary replication
         Primary-secondary replication methods
             > Statement-based replication
             > Write-ahead log (WAL) shipping
             > Logical (row-based) log replication
   - Multi-leader replication
         Handle conflicts
             > Conflict avoidance
             > Last-write-wins:  clock synchronization / clock skew
             > Custom logic
   - Peer-to-peer or leaderless replication
        Quorums: w+r>n

Data partitioning (or sharding)
   - Vertical sharding
        > used to increase the speed of data retrieval from a table consisting of columns with very wide text or a binary large object (blob)
   - Horizontal sharding
        > divide a table into multiple tables by splitting data row-wise
        > suitable to automate even under dynamic conditions
            - Key-range based sharding: The data routing logic uses the partition key at the application tier to map queries specified for a database shard
                Advantages:
                    > range-query-based scheme is easy to implement.
                    > Range queries can be performed using the partitioning keys, and those can be kept in partitions in sorted order.
                Disadvantages:
                    > Range queries can't be performed using keys other than the partitioning key.
                    > If keys aren't selected properly, some nodes may have to store more data due to an uneven distribution of the traffic.
            - Hash based sharding
                Advantages:
                    > Keys are uniformly distributed across the nodes.
                Disadvantages:
                    > We can't perform range queries with this technique. Keys will be spread over all partitions.
Consistent hashing
   - Advantages:
      > It's easy to scale horizontally.
      > It increases the throughput and improves the latency of the application.
   - Disadvantages:
      > Randomly assigning nodes in the ring may cause non-uniform distribution.
Re-balance the partitions
   - Avoid hash mod n
   - Fixed number of partitions:
      > create a higher number of partitions than the nodes
      > very important to choose the right number of partitions
      > used in Elasticsearch, Riak
   - Dynamic partitioning
      > when the size of a partition reaches the threshold, it’s split equally into two partitions
      > used in HBase and MongoD
   - Partition proportionally to nodes
      > the number of partitions is proportionate to the number of nodes, which means every node has fixed partitions
      > used by Cassandra and Ketama
Partitioning and secondary indexes
   Secondary indexes are the records that aren't identified by primary keys but are just a way of searching for some value.
      - Partition secondary indexes by document: local index
      - Partition secondary indexes by the term: global index
Request routing
   service discovery

ZooKeeper: a separate management server
Whenever there’s a change in the partitioning, or a node is added or removed, ZooKeeper gets updated and notifies the routing tier about the change.
HBase, Kafka and SolrCloud use ZooKeeper

disadvantages of a distributed database:
    - data is required from multiple sites, which takes more time than expected
    - operations such as joins need to reconstruct complete relations by carefully fetching data
    - difficult to maintain consistency of data across sites
    - Updates and backups in distributed databases take time to synchronize data
hotspots
------------------------------------------------------------------------------------------------------------------------

hardware failures and network congestion

Content consistency in CDN:
   - Periodic polling: time-to-refresh (TTR)
   - Time-to-live (TTL)
   - Leases: lease denotes the time interval for which the origin server agrees to notify the proxy server if there’s any change in the data
             lease renewal / expiration of the lease /  lease duration (adaptive lease)
------------------------------------------------------------------------------------------------------------------------
Sequencer / globally unique IDs
we need a unique ID generator that acts as a primary key in a distributed setting—for example, a horizontally-sharded table.

First solution: UUID: 128-bit number
                    Cons: Using 128-bit numbers as primary keys makes the primary-key indexing slower, which results in slow inserts.
                          A workaround might be to interpret an ID as a hex string instead of a number.
                          might not be monotonically increasing
                          can’t claim UUID to be deterministically unique / a chance of duplication
Second solution: using a database: auto-increment feature / modify the conventional auto-increment feature that increments by one to m

                           difficult to scale for multiple data centers
Third solution: using a range handler
                    Pros: scalable, available, and yields user IDs that have no duplicates.
                          maintain this range in 64 bits, which is numeric.
                    Cons: lose a significant range when a server dies

two types of physical clocks available in a computer:
    - the time-of-day clock
       > lower resolution in comparison to monotonic counters
       > Network Time Protocol (NTP) can move the clock forward or backward, so it's not always monotonic.
       > It may or may not incorporate leap seconds
    - monotonic counters
       > usually have higher resolution than time-of-day clocks
       > should be used for the duration between two events rather than for the time.
       > These aren't meaningful across different nodes.
       > NTP might adjust it without violating monotonicity.
       > NTP can only speed up or slow down the counter rate of change by up to 0.05%.

Physical clocks drift over time due to many reasons: Temperature differences / The equipment's age / Manufacturing defects / Virtualized clocks
physical clocks are unreliable. For such clocks, the error can be 17 seconds per day. In a distributed environment, the clocks won’t remain synced.
no matter how often we synchronize these clocks with each other or other clocks with accurate measurement methods, there will always be skew between the various clocks involved in a distributed system.

The Network Time Protocol (NTP) is a networking protocol for clock synchronization between computer systems over packet-switched, variable-latency data networks.
NTP intends to synchronize all participating computers within a few milliseconds of Coordinated Universal Time (UTC). It mitigates the effects of variable network latency.

4th solution: Use UNIX time stamps
    - Pros: simple, scalable, and easy to implement. It also enables multiple servers to handle concurrent requests
    - Cons: For two concurrent events, the same time stamp is returned and the same ID can be assigned to them. This way, the IDs are no longer unique.
5th solution: Twitter Snowflake
    - Pros: Twitter Snowflake uses the time stamp as the first component. Therefore, they’re time sortable. The ID generator is highly available as well.
    - Cons: IDs generated in a dead period are a problem.
            Another weak point of this system is its reliance on time
6th solution: Using logical clocks (Lamport and vector clocks) that need monotonically increasing identifiers for events.
    - Lamport clocks
        >  Cons: can't simply compare two clock values on any server to infer happened-before relationship
    - Vector clocks
        > Pros: maintain causal history—that is, all information about the happened-before relationships of events
7th solution: TrueTime API: Google’s TrueTime API in Spanner / reports an interval of time
                            Google deploys a GPS receiver or atomic clock in each data center, and clocks are synchronized within about 7 ms
    - Pros: We're able to generate a globally unique 64-bit identifier. The causality of events is maintained. The approach is scalable and highly available.
    - Cons: If two intervals overlap, then we’re unsure in what order A and B occurred.
            Spanner is expensive because it ensures high database consistency
------------------------------------------------------------------------------------------------------------------------
RESHADED Approach for System Design
Requirements / Estimation / Storage schema (optional) / High-level design / API design / Detailed design / Evaluation / Distinctive component/feature
------------------------------------------------------------------------------------------------------------------------









